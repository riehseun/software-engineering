{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph search, Shortest path, and Data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic graph search\n",
    "\n",
    "- find everything findable from a given start vertex\n",
    "- don't explore anything twice\n",
    "\n",
    "```\n",
    "genericAlgorithm(graph G, vertex s)\n",
    "- initially s explored, all other vertices unexplored\n",
    "- while possible\n",
    "    - choose an edge (u, v) with u explored and v unexplored (if none, halt)\n",
    "    - mark v explored\n",
    "```\n",
    "\n",
    "- claim: at the end of algorithm, $v$ explored iff $G$ has path from $s$ to $v$\n",
    "- proof: (=>) easy proof by induction. (<=) by contradiction. suppose $G$ has path $P$ from $s$ to $v$ but $v$ unexplored at the end of algorithm. then there exists an edge $(u,x)$ in $P$ such that $u$ explored and $v$ unexplored. but then algorithm would not have terminated  \n",
    "\n",
    "## BFS\n",
    "\n",
    "- explore ndoes in \"layers\"\n",
    "- can compute shortest path\n",
    "- can compute connected components of undirected graph\n",
    "- $O(n+m)$ using queue\n",
    "\n",
    "```\n",
    "BFS(graph G, start vertex s)\n",
    "- [all node initially unexplored]\n",
    "- mark s as explored\n",
    "- let Q = queue initialized with s\n",
    "- while Q is not empty:\n",
    "    - remove first node of Q, call it v\n",
    "    - for each edge (v, w)\n",
    "        - if w unexplored\n",
    "            - mark w as explored\n",
    "            - add w to Q (at the end)\n",
    "```\n",
    "\n",
    "- claim: at the end of BGS, $v$ explored iff $G$ has path from $s$ to $v$\n",
    "- proof: special case of generic algorithm\n",
    "- claim: run time is $O(n+m)$\n",
    "- proof: inspection of code\n",
    "\n",
    "### Application - Shortest path\n",
    "\n",
    "- compute dist(v), the fewest number of edges on path from $s$ to $v$\n",
    "- assumption: every edge has length of 1 \n",
    "- extra code to BFS\n",
    "\n",
    "```\n",
    "- initialize dist(v): 0 if v=s, large number if v != s\n",
    "- when considering edge (v,w)\n",
    "    - if w unexplored, then set dist(w) = dist(v) + 1 \n",
    "```\n",
    "\n",
    "### Application - Undirected connectivity\n",
    "\n",
    "- let $G(V,E)$ undirected graph\n",
    "- connected component = $pieces of G$\n",
    "- compute all connected components\n",
    "\n",
    "```\n",
    "- initalize: all nodes unexplored\n",
    "- assume labelled 1 to n\n",
    "- for i = 1 to n\n",
    "    - if i not explored # in some previsou BFS\n",
    "        - BFS(G, i) # discovers precisely i's connected component\n",
    "```\n",
    "\n",
    "## DFS\n",
    "\n",
    "- expllore aggressively, only backtrack when necessary\n",
    "- can compute topological ordering of directed acyclic graph\n",
    "- can compute strongly connected components of directed graph\n",
    "- $O(n+m)$ using stack\n",
    "\n",
    "```\n",
    "DFS(graph G, start vertex s)\n",
    "- mark s as explored\n",
    "- for every edge (s, v)\n",
    "    - if v is unexplored\n",
    "        - DFS(G, v)\n",
    "```   \n",
    "   \n",
    "### Application - Topological ordering\n",
    "\n",
    "- label $f$ on nodes of $G$ such that\n",
    "    - $f(v)$'s are the set {1,2,...,n}\n",
    "    - $(u,v) \\in G$ => $f(n) \\le f(v)$\n",
    "- let $v$ a sink vertex of $G$ (every directed graph has a sink vertex)\n",
    "- set $f(v) = n$\n",
    "- recurse on $G - \\{v\\}$\n",
    "- if $G$ has directed cycle, then there is no topological ordering\n",
    "- if $G$ does not have directed cycle, then computes topological ordering in $O(m+n)$\n",
    "\n",
    "```\n",
    "DFS_loop(graph G) \n",
    "- mark all nodes unexplored\n",
    "- current_label = n # keep track of ordering\n",
    "- for each vertext v in G\n",
    "    - if v not explored\n",
    "        - DFS(G,v)\n",
    "\n",
    "DFS(graph G, start vertex s)\n",
    "- mark s as explored\n",
    "- for every edge (s, v)\n",
    "    - if v is unexplored\n",
    "        - mark v explored\n",
    "        - DFS (G, v)\n",
    "- set f(s) = current_label\n",
    "- current_label--\n",
    "```\n",
    "\n",
    "Correctness\n",
    "- need to show that if $(u,v)$ is on edge, then $f(u) \\lt f(v)$\n",
    "- case #1: $u$ is visited by DFS before $v$. then recursive call corresponding to $v$ finishes before $u$, $f(v) \\gt f(u)$\n",
    "- case #2: $v$ is visited by DFS before $u$. then recursive call corresponding to $v$ finishes before $u$ even starts, $f(v) \\gt f(u)$\n",
    "\n",
    "### Application - Strongly connected components\n",
    "\n",
    "- there exist path $u \\rightarrow v$ and $v \\rightarrow u$ in graph G\n",
    "\n",
    "Kosaraju's two pass algorithm\n",
    "- compute SCC in $O(m+n)$\n",
    "- let $G^{'} = G$ with all arcs reversed\n",
    "- run DFS_loop on $G^{'}$ (compute magical ordering of nodes)\n",
    "- run DFS_loop on $G$ (compute strongly connected component one by one)\n",
    "\n",
    "```\n",
    "DFS_loop(graph G)\n",
    "- global variable t=0 # number of nodes processed so far\n",
    "- global variable s=null # current source vertex\n",
    "- assumes nodes labelled 1 to n\n",
    "- for i = n to 1\n",
    "    - if i not explored \n",
    "        - s = i\n",
    "        - DFS(G, i)\n",
    "        \n",
    "DFS(graph G, node i)\n",
    "- mark i as explored\n",
    "- set leader(i) = node s\n",
    "- for each arc (i,j) in G\n",
    "    - if j not explored\n",
    "        - DFS(G, j)\n",
    "- t++\n",
    "- set f(i) = t # ith finishing time\n",
    "```\n",
    "\n",
    "Correctness\n",
    "- claim: SCC of a directed graph $G$ induces an acyclic \"meta-graph\"\n",
    "- notice SCCs of original graph $G$ and its reversal $G^{'}$ are exactly the same\n",
    "- lemma: consider two \"adjacent\" SCCs in $G$. let $f(v)$ = finishing times of DFS_loop in $G^{'}$. then $max_{v \\in C_{1}} f(v) \\lt max_{v \\in C_{2}} f(v)$\n",
    "- corollary: maximum f-value of $G$ must lie in a \"sink SCC\"\n",
    "- by corollary, 2nd DFS_loop begins somewhere in a sink SCC $C^{*}$ \n",
    "    - first call to DFS discovers $C^{*}$, nothing else\n",
    "    - rest of DFS_loop like recursing on $G$ with $C^{*}$ deleted\n",
    "    - successive calls to DFS(G,i) \"peel off\" the SCCs one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import collections\n",
    "import sys\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_ordering(graph, node, ordering, explored_ordering):\n",
    "    \"\"\"\n",
    "    Perform depth first search on graph starting at the given node in order to compute 'magical ordering'\n",
    "\n",
    "    Args:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    node (integer) -- node to start searching\n",
    "    ordering (dictionary) -- represents finishing order of each node\n",
    "    explored_ordering (set) -- stores already explored nodes\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    explored_ordering.add(node)\n",
    "    if node in graph: # if node has outgoing edge(s)\n",
    "        for vertex in graph[node]: # loop through outgoing vertices of given node\n",
    "            if vertex not in explored_ordering:\n",
    "                DFS_ordering(graph, vertex, ordering, explored_ordering)\n",
    "    \n",
    "    ordering[node] = len(ordering) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_loop_ordering(graph, max_integer, ordering, explored_ordering):\n",
    "    \"\"\"\n",
    "    Perform depth first search for all nodes from max_integer to 1 in order to compute 'magical ordering'\n",
    "\n",
    "    Args:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    max_integer (integer) -- number of nodes to perform searching\n",
    "    ordering (dictionary) -- represents finishing order of each node\n",
    "    explored_ordering (set) -- stores already explored nodes\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    i = max_integer\n",
    "    while i > 0:\n",
    "        if i not in explored_ordering:\n",
    "            DFS_ordering(graph, i, ordering, explored_ordering)\n",
    "        i = i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_computing(graph, node, leader, explored_computing, s):\n",
    "    \"\"\"\n",
    "    Perform depth first search on graph starting at the given node in order to compute 'leaders' for strongly connected components\n",
    "\n",
    "    Args:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    node (integer) -- node to start searching\n",
    "    leader (list) -- leader nodes of strongly connected components\n",
    "    explored_computing (set) -- stores already explored nodes\n",
    "    s (list) -- leader node of a strongly connected component\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    explored_computing.add(node)\n",
    "    leader.append(s[0])\n",
    "    if node in graph: # if node has outgoing edge(s)\n",
    "        for vertex in graph[node]: # loop through outgoing vertices of given node\n",
    "            if vertex not in explored_computing:\n",
    "                DFS_computing(graph, vertex, leader, explored_computing, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_loop_computing(graph, max_integer, leader, explored_computing, s):\n",
    "    \"\"\"\n",
    "    Perform depth first search for all nodes from max_integer to 1 in order to compute 'leaders' for strongly connected components\n",
    "\n",
    "    Args:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    max_integer (integer) -- number of nodes to perform searching\n",
    "    leader (list) -- leader nodes of strongly connected components\n",
    "    explored_computing (set) -- stores already explored nodes\n",
    "    s (list) -- leader node of a strongly connected component\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    i = max_integer\n",
    "    s[0] = 0\n",
    "    while i > 0:\n",
    "        if i not in explored_computing:\n",
    "            s[0] = i\n",
    "            DFS_computing(graph, i, leader, explored_computing, s)\n",
    "        i = i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(graph, node):\n",
    "    \"\"\"\n",
    "    Get all outgoing vertices from given node\n",
    "\n",
    "    Args:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    node (integer) -- node to find outgoing vertices\n",
    "\n",
    "    Returns:\n",
    "    vertices (set) -- all outgoing vertices from given node\n",
    "    \"\"\"\n",
    "\n",
    "    vertices = set()\n",
    "    for arc in graph:\n",
    "        if arc[0] == node:\n",
    "            vertices.add(arc[1])\n",
    "            \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max(graph):\n",
    "    \"\"\"\n",
    "    Computes maximum number from the given graph\n",
    "\n",
    "    Args:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "\n",
    "    Returns:\n",
    "    max_num (integer) -- maximum number from given graph\n",
    "    \"\"\"\n",
    "\n",
    "    temp_list = []\n",
    "    for edge in graph:\n",
    "        temp_list.append(max(edge[0], edge[1]))\n",
    "\n",
    "    max_num = max(temp_list)\n",
    "    return max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_graph_as_list(file_path):\n",
    "    \"\"\"\n",
    "    Imports a file and stored data into a list of lists\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file\n",
    "\n",
    "    Returns:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    \"\"\"\n",
    "\n",
    "    graph = []\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array = line.read().split(\"\\n\")\n",
    "        for subarray in array:\n",
    "            graph.append(subarray.split(\" \"))\n",
    "\n",
    "    for arc in graph:\n",
    "        arc[0] = int(arc[0])\n",
    "        arc[1] = int(arc[1])\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_graph_to_dict(graph_list):\n",
    "    \"\"\"\n",
    "    Imports a file and stored data into a dictionary\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file\n",
    "\n",
    "    Returns:\n",
    "    graph (dictionary) -- adjacency represeantaion of graph\n",
    "    \"\"\"\n",
    "\n",
    "    graph_dict = {}\n",
    "\n",
    "    for arc in graph_list:\n",
    "        key = int(arc[0])\n",
    "        value = int(arc[1])\n",
    "        if key not in graph_dict:\n",
    "            graph_dict[key] = set()\n",
    "            graph_dict[key].add(value)\n",
    "        else:\n",
    "            graph_dict[key].add(value)\n",
    "\n",
    "    return graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strongly_connected_component():\n",
    "    \"\"\"\n",
    "    Compute strongly connected components\n",
    "\n",
    "    Args:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    ordering = {} # dictionary to store magical ordering. dictionary is to have O(1) for loopkup\n",
    "    explored_ordering = set() # set to store explored nodes. set is to have O(1) for loopkup\n",
    "    \n",
    "    leader = []\n",
    "    explored_computing = set()\n",
    "    s = []\n",
    "    s.append(-1) # leaders in second path\n",
    "\n",
    "    # Convert graph (list) to graph(dictionary) to have O(1) for looking up outgoing vertices from given node\n",
    "    graph_dict = convert_graph_to_dict(graph_list) \n",
    "    \n",
    "    # Data is provided such that nodes are labelled from 1 to max_integer\n",
    "    max_integer = compute_max(graph_list) \n",
    "    \n",
    "    # Compute the magical ordering\n",
    "    DFS_loop_ordering(graph_dict, max_integer, ordering, explored_ordering) \n",
    "    \n",
    "    # Reverse direction of graph (~ 10 seconds)\n",
    "    for edge in graph_list:\n",
    "        tmp = edge[0]\n",
    "        edge[0] = edge[1]\n",
    "        edge[1] = tmp\n",
    "\n",
    "    # Change nodes based on magical ordering\n",
    "    for i in range(0, len(graph_list)):\n",
    "        graph_list[i][0] = ordering.get(graph_list[i][0])\n",
    "        graph_list[i][1] = ordering.get(graph_list[i][1])\n",
    "\n",
    "    graph_dict = convert_graph_to_dict(graph_list)\n",
    "    DFS_loop_computing(graph_dict, max_integer, leader, explored_computing, s)\n",
    "\n",
    "    # Show the result\n",
    "    counter = collections.Counter(leader)\n",
    "    result = \"\"\n",
    "    for tuple_item in counter.most_common(5):\n",
    "        result += str(tuple_item[1])\n",
    "        result += \",\"\n",
    "    print(result[:-1])\n",
    "    return result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = open_graph_as_list(\"data/strongly-connected-component1.txt\")\n",
    "assert(strongly_connected_component() == \"3,3,3\")\n",
    "\n",
    "graph_list = open_graph_as_list(\"data/strongly-connected-component2.txt\")\n",
    "assert(strongly_connected_component() == \"3,3,2\")\n",
    "\n",
    "graph_list = open_graph_as_list(\"data/strongly-connected-component3.txt\")\n",
    "assert(strongly_connected_component() == \"3,3,1,1\")\n",
    "\n",
    "graph_list = open_graph_as_list(\"data/strongly-connected-component4.txt\")\n",
    "assert(strongly_connected_component() == \"7,1\")\n",
    "\n",
    "graph_list = open_graph_as_list(\"data/strongly-connected-component5.txt\")\n",
    "assert(strongly_connected_component() == \"6,3,2,1\")\n",
    "\n",
    "graph_list = open_graph_as_list(\"data/strongly-connected-component.txt\")\n",
    "sys.setrecursionlimit(8000000)\n",
    "threading.stack_size(67108864)\n",
    "thread = threading.Thread(target=strongly_connected_component)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path (Dijkstra's Algorithm)\n",
    "\n",
    "Single-source shortest path\n",
    "- input: directed graph $G = (V,E)$\n",
    "    - each edge has non-negative length $l_{e}$\n",
    "    - source vertex $s$\n",
    "- output: for each $v \\in V$, compute $L(v)$ = length of a shortest $s$-$v$ path in $G$\n",
    "\n",
    "BFS computes shortest paths in linear time if $l_{e} = 1$ for every edge $e$. We can replace each edge $e$ by a number of $l_{e}$ with unit length, but it blows up graph too much\n",
    "\n",
    "### Implementation (run in $O(nm)$)\n",
    "- $X = \\{s\\}$ # vertices processed so far\n",
    "- $A[s] = 0$ # computed shortest path distances\n",
    "- $B[s] = null$ # computed shortest path (actial path like a->b->c)\n",
    "- while $X$ != $V$ # assume there are two sets $X$ and $V-X$ \n",
    "    - among all edges $(v,w) \\in E$ with $v \\in X$, $w \\notin X$, pick the one that minimizes $A[v]$ + $l_{vw}$ # call it $(v^{*}, w^{*})$\n",
    "    - add $w^{*}$ to $X$\n",
    "    - set $A[w^{*}]$ = $A[v^{*}] + l_{v^{*}w^{*}}$\n",
    "    - set $B[w^{*}]$ = $B[v^{*}] + (v^{*}, w^{*})$\n",
    "    \n",
    "Why can't add a large number to $l_{e}$ if there are edges with negative length? because it does not preserve the shortest path\n",
    "\n",
    "### Correctness\n",
    "- claim: for every directed graph with non-negative edge length, Dijkstra's algorithm correctly computes all shortest path distances. In other words, $A[v] = L(v), \\forall{v} \\in V$ where $A[v]$ = what algorithm computes and $L(v)$ = true shortest distance\n",
    "- proof\n",
    "    - base case $A[s] = L[s] = 0$\n",
    "    - assume $A[v] = L[v]$ and $B[v]$ = true shortest $s$-$v$ path in $G$, for all $v$ already in $X$\n",
    "    - then, \n",
    "        - we pick an edge $(v^{*}, w^{*})$ and we add $w^{*}$ to $X$. \n",
    "        - we set $B[w^{*}]$ = $B[v^{*}] + (v^{*}, w^{*})$ = an $s$->$w^{*}$ path with length $L(v^{*}) + l_{v^{*}w^{*}}$\n",
    "        - need to show every $s$-$w^{*}$ path has length $\\ge L(v^{*}) + l_{v^{*}w^{*}}$  \n",
    "            - let $P$ = any $s$-$w^{*}$ path\n",
    "            - then $s \\rightarrow y \\in X \\rightarrow z \\notin X \\rightarrow w^{*} \\notin X$ \n",
    "            - then $A[v^{*}] + l_{v^{*}w^{*}} \\le A[y] + l_{yz} \\le$ length of $P$\n",
    "            \n",
    "### Heap\n",
    "- perfectly balanced tree\n",
    "- at every node, key $\\le$ children's keys\n",
    "- Extract-Min by swapping up last leaf, bubbling down\n",
    "- insert via bubbling up\n",
    "\n",
    "Two invariants\n",
    "1. elements in heap = vertices of $V-X$\n",
    "2. for $v \\notin X$, $key[v]$ = smallest Dijkstra greedy score of an edge $(u,v)$ in $E$ with $v \\in X$\n",
    "\n",
    "By this, Extract-Min yields correct vertex $w^{*}$ to add to $X$ next (and we set $A[w^{*}]$ to $key[w^{*}]$)\n",
    "\n",
    "To maintain invariant #2, when $w$ extracted from heap (added to $X$)\n",
    "- for each edge $(w,v)$ in $E$\n",
    "    - if $v$ in $V-X$ (in heap)\n",
    "        - delete $v$ from heap\n",
    "        - re-compute $key[v]$ = $min\\{key[v], A[w]+l_{wv}\\}$\n",
    "        - re-insert $v$ into heap\n",
    "        \n",
    "Runtime analysis\n",
    "- $(n-1)$ Extract-Mins\n",
    "- each edge $(v,w)$ triggers at most one delete/insert combo (if $v$ added to $X$ first)\n",
    "- number of heap operations in $O(n+m) = O(m)$ (since graph is weakly connected)\n",
    "- runtime = $O(mlogn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_graph(file_path):    \n",
    "    \"\"\"\n",
    "    Imports a file and stored data into a list of lists\n",
    "    \n",
    "    Args:\n",
    "    file_path (string) -- location of file\n",
    "    \n",
    "    Returns:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    \"\"\"\n",
    "    \n",
    "    graph = []\n",
    "    \n",
    "    with open(file_path, 'r') as line:\n",
    "        array = line.read().split(\"\\n\")\n",
    "        for subarray in array:\n",
    "            graph.append(subarray.split(\"\\t\"))\n",
    "    \n",
    "    for i in range(0, len(graph)):\n",
    "        del graph[i][-1]\n",
    "    del graph[-1]\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(graph, source_vertex):\n",
    "    \"\"\"\n",
    "    Get all possible outgoing vertices from a given vertex\n",
    "    \n",
    "    Args:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    source_vertex (string) -- given vertex\n",
    "    \n",
    "    Returns:\n",
    "    vertices (list) -- all possible outgoing vertices\n",
    "    \"\"\"\n",
    "    \n",
    "    vertices = []\n",
    "    \n",
    "    for elem in graph:\n",
    "        if elem[0] == source_vertex:\n",
    "            for i in range(1, len(elem)):\n",
    "                vertices.append(elem[i].split(\",\")[0])\n",
    "    \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_outgoing_path(graph, X):\n",
    "    \"\"\"\n",
    "    For all nodes in X, find outgoing vertices that are not in X\n",
    "    \n",
    "    Args: \n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    X (list) -- all explored vertices\n",
    "    \n",
    "    Returns:\n",
    "    candidates (list) -- all outgoing vertices, that are not in X, for all vertices in X\n",
    "    \"\"\"\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    for vertex1 in X:\n",
    "        outgoing = get_next(graph, vertex1)\n",
    "        for vertex2 in outgoing:\n",
    "            if vertex2 not in X:\n",
    "                candidates.append((vertex1, vertex2))\n",
    "            \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_for_source_vertex(candidates, destination_vertex):\n",
    "    \"\"\"\n",
    "    Find all source vertices whose outgoing vertices are the final destination vertex\n",
    "    \n",
    "    Args:\n",
    "    candidates (list) -- all outgoing vertices, that are not in X, for all vertices in X\n",
    "    destination_vertex (string) -- final destination vertex\n",
    "    \n",
    "    Returns:\n",
    "    candidates_for_source_vertex (list) -- all vertices whose outgoing vertices are the final destination vertex\n",
    "    \"\"\"\n",
    "\n",
    "    candidates_for_source_vertex = []\n",
    "    \n",
    "    for edge in candidates:\n",
    "        if edge[1] == destination_vertex:\n",
    "            candidates_for_source_vertex.append(edge[0])\n",
    "    return candidates_for_source_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(graph, source_vertex, destination_vertex):\n",
    "    \"\"\"\n",
    "    Find cost between vertices\n",
    "    \n",
    "    Args:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    source_vertex (string) -- a given vertex\n",
    "    destination_vertex (string) -- an outgoing vertex for given vertex\n",
    "    \n",
    "    Returns:\n",
    "    cost (integer) -- cost between given and outgoing vertices\n",
    "    \"\"\"\n",
    "\n",
    "    cost = -1\n",
    "    for elem in graph:\n",
    "        if elem[0] == source_vertex:\n",
    "            for i in range(1, len(elem)):\n",
    "                if elem[i].split(\",\")[0] == destination_vertex:\n",
    "                    cost = elem[i].split(\",\")[1]\n",
    "    return int(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_minimum(graph, A, X, candidates):    \n",
    "    \"\"\"\n",
    "    For all outgoing vertices from X, find an outgoing vertex that would incur the minimum cost. Then update X and A\n",
    "    \n",
    "    Args:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    A (dictionary) -- key represents a vertex and value represents the cost from the initial source vertex to this vertex\n",
    "    X (list) -- all explored vertices\n",
    "    candidates (list) -- all outgoing vertices, that are not in X, for all vertices in X\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    minimum_distance = 1000000\n",
    "    minimum_vertex2 = \"\"\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        vertex1 = candidate[0] # this vertex is in X\n",
    "        vertex2 = candidate[1] # this vertex is not in X\n",
    "        \n",
    "        for elem in graph:\n",
    "            if elem[0] == vertex1:\n",
    "                for i in range(1, len(elem)):\n",
    "                    if elem[i].split(\",\")[0] == vertex2:\n",
    "                        index_of_vertex1 = X.index(vertex1)\n",
    "                        if A[vertex1] + int(elem[i].split(\",\")[1]) < minimum_distance:\n",
    "                            minimum_distance = A[vertex1] + int(elem[i].split(\",\")[1])\n",
    "                            minimum_vertex2 = elem[i].split(\",\")[0]\n",
    "    \n",
    "    A[minimum_vertex2] = minimum_distance\n",
    "    X.append(minimum_vertex2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(graph, source_vertex, destination_vertex, A, X, init=False):\n",
    "    \"\"\"\n",
    "    Compute the shortest path algorithm on a directed graph\n",
    "    \n",
    "    Args:\n",
    "    graph (list of lists) -- adjacency representation of graph \n",
    "    source_vertex (string) -- initial vertex to start from\n",
    "    destination_vertex (string) -- final vertex to end\n",
    "    A (dictionary) -- key represents a vertex and value represent the cost from the initial source vertex to that vertex\n",
    "    X (list) -- all explored vertices\n",
    "    init (string) -- flag to determin whether to initialize A and X\n",
    "    \n",
    "    Returns:\n",
    "    A[destination_vertex] (integer) -- cost from the source vertex to the final destination vertex\n",
    "    \"\"\"\n",
    "\n",
    "    if init:\n",
    "        A[source_vertex] = 0 # distance from source_vertex to itself is 0\n",
    "        X.append(source_vertex) # source_vertex is the first vertext in the set\n",
    "\n",
    "    candidates = get_all_outgoing_path(graph, X)\n",
    "    if destination_vertex not in X and len(X) < len(graph):\n",
    "        pick_minimum(graph, A, X, candidates)\n",
    "        shortest_path(graph, X[-1], destination_vertex, A, X)\n",
    "        \n",
    "    # If there is no path between the original source and destination\n",
    "    if destination_vertex not in X: \n",
    "        A[destination_vertex] = 1000000\n",
    "\n",
    "    return A[destination_vertex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = open_graph(\"data/shortest-path.txt\")\n",
    "assert(shortest_path(graph, \"1\", \"7\", {}, [], True) == 2599)\n",
    "assert(shortest_path(graph, \"1\", \"37\", {}, [], True) == 2610)\n",
    "assert(shortest_path(graph, \"1\", \"59\", {}, [], True) == 2947)\n",
    "assert(shortest_path(graph, \"1\", \"82\", {}, [], True) == 2052)\n",
    "assert(shortest_path(graph, \"1\", \"99\", {}, [], True) == 2367)\n",
    "assert(shortest_path(graph, \"1\", \"115\", {}, [], True) == 2399)\n",
    "assert(shortest_path(graph, \"1\", \"133\", {}, [], True) == 2029)\n",
    "assert(shortest_path(graph, \"1\", \"165\", {}, [], True) == 2442)\n",
    "assert(shortest_path(graph, \"1\", \"188\", {}, [], True) == 2505)\n",
    "\n",
    "\n",
    "assert(shortest_path(graph, \"1\", \"197\", {}, [], True) == 3068)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "- organize data so that it can be accessed quickly and usefully\n",
    "- ex: list, stack, queue, heap, search tree, hashtable, bloom filter, union-find, etc\n",
    "- choose the \"minimal\" data structure that supports all the operations that you need\n",
    "\n",
    "## Heap (a.k.a priority queue)\n",
    "\n",
    "- a container for objects that have keys\n",
    "- ex: employer records, network edges, events, etc\n",
    "\n",
    "Operatons\n",
    "- insert: add a new object to heap $O(nlogn)$\n",
    "- extract: remove an object with minimum key valye $O(nlogn)$\n",
    "- heapify: $n$ batched inserts $O(n)$\n",
    "- delete: $O(nlogn)$\n",
    "\n",
    "Property\n",
    "- think of a heap as a tree: rooted, binary, as complete as possible\n",
    "- at every node $x$, $key[x] \\le$ all keys in $x$'s children\n",
    "- object at root must have minimum key value\n",
    "\n",
    "Array implementation\n",
    "- Put node in the tree into array layer by layer\n",
    "- parent$(i)$ = $i/2$ if $i$ is even, floor$(i/2)$ if $i$ is odd\n",
    "- children$(i)$ = $2i$ and $2i + 1$\n",
    "\n",
    "```\n",
    "Insert(key k)\n",
    "- stick k at the end of last level\n",
    "- bubble-up k until k's parent <= k\n",
    "```\n",
    "\n",
    "```\n",
    "Extract-Min\n",
    "- delete root\n",
    "- move last node to new root\n",
    "- bubble-down k until k's parent <= k\n",
    "```\n",
    "\n",
    "### Application - heapsort\n",
    "\n",
    "- insert all $n$ array elements into a heap  \n",
    "- extract-min to pluck out elements in sorted order \n",
    "- $O(nlogn)$\n",
    "\n",
    "### Application - event manager\n",
    "\n",
    "- objects: event records\n",
    "- key: time event scheduled to occur\n",
    "- extract-min: yields the next scheduled event\n",
    "\n",
    "### Application - median maintenance\n",
    "\n",
    "- given a sequence $x_{1} \\dots x_{n}$ of numbers coming one at a time, find median of $\\{x_{1} \\dots x_{i}\\}$ at each time step $i$\n",
    "- $H_{low}$: supports extract-min\n",
    "- $H_{high}$: supports extract-max\n",
    "- maintain invariant that $i/2$ smallest element in $H_{low}$ (or $i/2$ largest element in $H_{high}$)\n",
    "\n",
    "### Sorted array\n",
    "\n",
    "- search: $O(logn)$\n",
    "- select(given order statistic $i$): $O(1)$\n",
    "- min/max: $O(1)$\n",
    "- pred/succ (given pointer to a key): $O(1)$\n",
    "- rank (number of kyes less than or equal to a given value): $O(logn)$\n",
    "- output in sorted order: $O(n)$\n",
    "- insert/delete: $O(n)$\n",
    "\n",
    "### Balanced search tree (sorted array with fast insert & delete)\n",
    "\n",
    "- search: $O(logn)$\n",
    "- select: $O(logn)$\n",
    "- min/max: $O(logn)$\n",
    "- pred/succ: $O(logn)$\n",
    "- rank: $O(logn)$\n",
    "- output in sorted order: $O(n)$\n",
    "- insert/delete: $O(logn)$\n",
    "\n",
    "### Binary search tree \n",
    "\n",
    "- exactly one node per key\n",
    "- each node has\n",
    "    - left child pointer\n",
    "    - right child pointer\n",
    "    - parent\n",
    "- all nodes left on node $X$ are less than $X$\n",
    "- all nodes right on node $X$ are greater than $X$\n",
    "- many possible trees for a set of keys\n",
    "- height could be anywhere from $log_{2}n$ to $n$\n",
    "- generally operations are $O(height)$\n",
    "\n",
    "```\n",
    "Search(key k)\n",
    "- start at the root\n",
    "- traverse left (if k < key at current node) or right (if k > key at current node) child pointers as needed\n",
    "- return node with key k or NULL, as appropriate\n",
    "```\n",
    "\n",
    "```\n",
    "Insert(key k)\n",
    "- start at the root\n",
    "- do search (which will return NULL)\n",
    "- rewire final NULL pointer to point to new node with key k\n",
    "```\n",
    "\n",
    "```\n",
    "Min/Max\n",
    "- start at the root\n",
    "- follow left (min case) or right (max case) until the bottom (return last key found)\n",
    "```\n",
    "\n",
    "```\n",
    "Pred(key k)\n",
    "- easy case: if k's left subtree nonempty, return max key in left subtree\n",
    "- otherwise: follow parent pointers until you get to a key less than k\n",
    "```\n",
    "\n",
    "```\n",
    "Inorder traversal\n",
    "- to print out keys in increasing order\n",
    "- let r = root, Tr = right subtree, Tl = left subtree\n",
    "- recurse on Tl\n",
    "    - by recursion, prints out keys of TL in increasing order\n",
    "- print out r's key\n",
    "- recurse on Tr\n",
    "    - by recursion, prints out keys of TR in increasing order\n",
    "```\n",
    "\n",
    "```\n",
    "Delete(key k)\n",
    "- search for k\n",
    "- if k has no children \n",
    "    - delete k\n",
    "- k has one child\n",
    "    - delete k, and put child under k's parent\n",
    "- k has two children \n",
    "    - compute k's predecessor l\n",
    "        - for example, traverse k's (non-NULL) left child pointer, then right child pointers until no longer possible\n",
    "    - swap k and l\n",
    "    - delete k\n",
    "```\n",
    "\n",
    "```\n",
    "Select(order statistic i )\n",
    "- store a little bit of extra info at each tree node about the tree itself\n",
    "- start at root x, with children y and z\n",
    "- let a = size(y) # a = 0 if x has no left child\n",
    "- if a = i-1\n",
    "    - return x's key\n",
    "- if a >= i\n",
    "    - recurse to compute ith order statistic on new root y\n",
    "- if a < i-1\n",
    "    - recurse to compute (i-a-1)th order statistic on new root z\n",
    "```\n",
    "\n",
    "### Balanced search tree \n",
    "\n",
    "- ensure that heights are $O(logn)$ so that search/insert/delete/min/max/pred/succ will run in $O(logn)$\n",
    "- ex: red-black tree, AVL, splay tree, B tree\n",
    "\n",
    "### Red-Black invariants\n",
    "\n",
    "1. each node red or black\n",
    "2. root is black\n",
    "3. no 2 reds in a row (red node => only black children)\n",
    "4. every root-NULL path (unsuccessful search) has the same number of black nodes\n",
    "\n",
    "### Height guarantee\n",
    "\n",
    "- claim: every red-black tree with $n$ nodes has height $\\le 2log_{2}(n+1)$ \n",
    "- proof: \n",
    "    - if every root-NULL path has $\\ge k$ nodes, then tree includes (at the top) a perfectly balanced search tree of depth $k-1$\n",
    "    - thus, size $n$ of the tree must be at least $2^{k}-1$\n",
    "    - then, $k \\le log_{2}(n+1)$\n",
    "    - then, there is a root-NULL path with at most $log_{2}(n+1)$ black nodes\n",
    "    - by invariant 4, every root-NULL path has $\\le log_{2}(n+1)$ black nodes\n",
    "    - by invariant 3, every root-NULL path has $\\le log_{2}(n+1)$ total nodes\n",
    "    \n",
    "### Rotation\n",
    "\n",
    "- locally rebalance subtrees at a node in $O(1)$ time\n",
    "- left rotation\n",
    "- right rotation\n",
    "\n",
    "### Insertion in a Red-Black tree\n",
    "\n",
    "- proceed as in a normal binary search tree, then recolor and (or perform rotation) until invariants are restored\n",
    "\n",
    "```\n",
    "Insert(x)\n",
    "- insert x as usual (makes x a leaf)\n",
    "- try coloring x red\n",
    "- if x's parent y is black, done\n",
    "- else y is red, then y has a black parent w\n",
    "```\n",
    "\n",
    "case #1: the other child $z$ of $x$'s grand parent $w$ is also red\n",
    "- recolor $y,z$ black and $w$ red (this does not break invariant 4)\n",
    "- either restores invariant 3 or propagate the double red upward\n",
    "- can only happen $O(logn)$ times (if you reach the root, recolor it black => preserves invariant 4)\n",
    "\n",
    "case #2: let $x,y$ be the current double-red, $x$ the deeper node. let $w$ = $y$'s grand parent. suppose $w$'s other child (which is not equal to $y$) is NULL or is a black node $z$\n",
    "- can eliminate double-red (all invariants satisfied) in $O(1)$ time via 2-3 rotations + recolorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read file line by line\n",
    "    \n",
    "    Args:\n",
    "    file_path (string) -- location of file to be read\n",
    "    \n",
    "    Returns:\n",
    "    array (list) -- contains integers\n",
    "    \"\"\"\n",
    "    \n",
    "    array = []\n",
    "    \n",
    "    with open(file_path, 'r') as line:\n",
    "        array = line.read().split(\"\\n\")\n",
    "        \n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = int(array[i])\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_two_heaps(low_heap, high_heap):\n",
    "    \"\"\"\n",
    "    Adjusts two heaps such that lower half of set is in low_heap and upper half is in high_heap\n",
    "    \n",
    "    Args:\n",
    "    low_heap (list) -- heap that holds lower half of data\n",
    "    high_heap (list) -- heap that holds upper half of data\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    max_low_heap = max(low_heap)\n",
    "    min_high_heap = min(high_heap)\n",
    "    \n",
    "    if max_low_heap > min_high_heap:\n",
    "        min_high_heap_index = high_heap.index(min_high_heap)\n",
    "        del high_heap[min_high_heap_index]\n",
    "        high_heap.append(max_low_heap)\n",
    "        \n",
    "        max_low_heap_index = low_heap.index(max_low_heap)\n",
    "        del low_heap[max_low_heap_index]\n",
    "        low_heap.append(min_high_heap)\n",
    "        \n",
    "        adjust_two_heaps(low_heap, high_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_running_median(array):\n",
    "    \"\"\"\n",
    "    Computes running median of an input array\n",
    "    \n",
    "    Args:\n",
    "    array (list) -- contains numbers\n",
    "    \n",
    "    Returns:\n",
    "    median (list) -- contains running medians of an input array\n",
    "    \"\"\"\n",
    "    \n",
    "    low_heap = []\n",
    "    high_heap = []\n",
    "    median = []\n",
    "    \n",
    "    for i in array:\n",
    "        if len(low_heap) > len(high_heap):\n",
    "            high_heap.append(i)\n",
    "        else:\n",
    "            low_heap.append(i)\n",
    "\n",
    "        if len(high_heap) > 0 and len(low_heap) > 0:\n",
    "            adjust_two_heaps(low_heap, high_heap)\n",
    "\n",
    "        if len(high_heap) == 0:\n",
    "            median.append(low_heap[0])\n",
    "\n",
    "        if len(low_heap) == 0:\n",
    "            median.append(high_heap[0])\n",
    "\n",
    "        if len(high_heap) > 0 and len(low_heap) > 0:\n",
    "            median.append(max(low_heap))\n",
    "        \n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = open_file(\"data/median-maintenance.txt\")\n",
    "median = compute_running_median(array)\n",
    "assert(sum(median) % 10000 == 1213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash table\n",
    "\n",
    "- maintain (or evoling) set of stuff\n",
    "- ex: transactions, people + associated data, IP addresses\n",
    "- really a dictionary (w/o ordering elements)\n",
    "- Insert & Delete & Lookup: $O(1)$\n",
    "\n",
    "### Application - de-duplication\n",
    "\n",
    "- given a \"stream\" of objects, remove duplications\n",
    "- when new object $x$ arrives\n",
    "    - lookup $x$ in hash table $H$\n",
    "    - if not found, insert $x$ into $H$\n",
    "    \n",
    "### Application - 2-SUM problem\n",
    "\n",
    "- input: unsorted array $A$ of $n$ integers and target sum $t$\n",
    "- goal: determine whether or not there are two numbers $x,y$ in $A$ such that $x + y = t$\n",
    "- exhaustive search: $\\theta(n^{2})$\n",
    "- sort $A$, then for each $x$ in $A$, look for $t-x$ in $A$ via binary search: $\\theta(nlogn)$\n",
    "- insert elements of $A$ into hash table $H$, then for each $x$ in $A$, lookup $t-x$: $\\theta(n)$\n",
    "\n",
    "### High level idea\n",
    "\n",
    "- setup: universe $U$\n",
    "- goal: want to maintain evolving set $S \\subseteq U$\n",
    "- pick $n$ = number of \"buckets\"\n",
    "- choose a hash function $h: U -> \\{0,1,2 \\dots n-1\\}$\n",
    "- use array $A$ of length $n$, store $x$ in $A[h(x)]$\n",
    "\n",
    "### Resolving collisions\n",
    "\n",
    "- collision: distinct $x,y \\in U$ such that $h(x) = h(y)$ \n",
    "\n",
    "Solution #1: (separate) chaining\n",
    "- keep linked list in each bucket\n",
    "- given a key/object $x$, perform insert/delete/lookup in the list in $A[h(x)]$ where $A$ = linked list for $x$ and $h(x)$ = bucket for $x$\n",
    " \n",
    "Solution #2: open addressing (only one object per bucket)\n",
    "- hash function now specifies probe sequence $h_{1}(x), h_{2}(x) \\dots$ (keep trying till finding an open slot)\n",
    "- ex: linear probing (look consecutively), double hashing\n",
    " \n",
    "###  Good hash function\n",
    "- spread data out\n",
    "- easy to store\n",
    "- fast to evaluate\n",
    "\n",
    "### Universal hash function\n",
    "\n",
    "- the load of a hash table $\\alpha$ = (number of objects in hash table) / (number of buckets of hash table)\n",
    "    - $\\alpha = O(1)$ is necessary condition for operations to run in constant time\n",
    "    - with open addressing, need $\\alpha << 1$\n",
    "- good hash table performance\n",
    "    - need to control load\n",
    "    - need a good hash function\n",
    "    \n",
    "Problem\n",
    "- ideally we want hash function that guarantees to spread every data set out evenly, however for every hash function, there is a pathological data set\n",
    "\n",
    "Solution\n",
    "- use a cryptographic hash function (ex. SHA-2)\n",
    "    - infeasible to reverse engineer a pathological data set \n",
    "- use randomization\n",
    "    - design a family $H$ of hash functions such that for all data sets $S$, \"almost all\" functions $h \\in H$ spread $S$ out \"pretty evenly\"\n",
    "    \n",
    "Definition\n",
    "- let $H$ be a set of hash functions from $U$ to $\\{0,1,2 \\dots n-1\\}$\n",
    "- $H$ is universal iff for all $x,y$ in $U$ (with $x != y$)\n",
    "- $Pr_{h \\in H}[h(x) = h(y)] \\le \\dfrac{1}{n}$, $n$ = number of buckets, $h$ is chosen uniformly at random from $H$  \n",
    "\n",
    "### Example - hashing IP addresses\n",
    "\n",
    "- let $U$ = IP addresses of the form $(x_{1}, x_{2}, x_{3}, x_{4})$ with each $x_{i} \\in \\{0,1,2 \\dots 255\\}$\n",
    "- let $n$ = a prime (ex. small multiple of number of objects in hash table)\n",
    "- define one hash function $h_{a}$ per 4-tuple $a = (a_{1}, a_{2}, a_{3}, a_{4})$ with each $a_{i} \\in \\{0,1,2 \\dots n-1\\}$\n",
    "- $h_{a}$: IP addresses -> buckets by\n",
    "    - $h_{a}(x_{1}, x_{2}, x_{3}, x_{4}) = (a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{3} + a_{4}x_{4})$ mod $n$\n",
    "    - $H = \\{h_{a} | a_{1}, a_{2}, a_{3}, a_{4} \\in \\{0,1,2 \\dots n-1\\} \\}$\n",
    "- claim: this family is universal\n",
    "- proof:\n",
    "    - consider distinct IP addresses $(x_{1}, x_{2}, x_{3}, x_{4}), (y_{1}, y_{2}, y_{3}, y_{4})$\n",
    "    - assume $x_{4} != y_{4}$\n",
    "    - collision <=> $a_{1}x_{1} + a_{2} + x_{2} + a_{3} + x_{3} + a_{4}x_{4} = a_{1}y_{1} + a_{2} + y_{2} + a_{3} + y_{3} + a_{4} + y_{4}$ <=> $a_{4}(x_{4} - y_{4}) = \\displaystyle\\sum_{i=1}^{3}a_{i}(y_{i} - x_{i})$ mod $n$\n",
    "    - with $a_{1}, a_{2}, a_{3}$ fixed arbitrarily, how many choices of $a_{4}$ satisfy\n",
    "        - $a_{4}(x_{4} - y_{4}) = \\displaystyle\\sum_{i=1}^{3}a_{i}(y_{i} - x_{i})$ mod $n$\n",
    "    - notice that LHS is equally likely to be any of $\\{0,1,2 \\dots n-1\\}$ ($x_{4} != y_{4}$, $n$ is prime, $a_{4}$ uniform at random)\n",
    "    \n",
    "### Chaining: constant-time guarantee\n",
    "\n",
    "- scenario: hash table implemented with chaining. hash function $h$ chosen uniformly at random from universal family $H$\n",
    "- theorem: all operations run in $O(1)$ for every data set $S$\n",
    "- caveats:\n",
    "    - in expectation over the random choice of the hash function $h$\n",
    "    - assumes $|S| = O(n)$ (ex. load $\\alpha = \\dfrac{|S|}{n} = O(1)$)\n",
    "    - assumes $O(1)$ to evaluate hash function\n",
    "- proof: only analyze an unsuccessful lookup because other operations are faster\n",
    "    - let $S$ = data set with $|S| = O(n)$\n",
    "    - consider lookup for $X \\notin S$\n",
    "    - runtime: $O(1) + O$(list length in$A[h(x)])$ (compute $h(x)$ + traverse list)\n",
    "    - let $L$ = list length in $A[h(x)]$\n",
    "    - for $y \\in S$ (so $y != x$) define $z_{y} = 1$ if $h(y) = h(x)$, $0$ otherwise\n",
    "    - note $L = \\displaystyle\\sum_{y \\in S}A_{y}$\n",
    "    - so $E[L] = \\displaystyle\\sum_{y \\in S}E[z_{y}]$\n",
    "    - $E[z_{y}] = 0 * Pr[z_{y} = 0] + 1 * Pr[z_{y} = 1] = Pr[h(y) = h(x)]$\n",
    "    - $E[L] = \\displaystyle\\sum_{y \\in S}E[z_{y}] = \\displaystyle\\sum_{y \\in S}Pr[h(y) = h(x)] \\le \\displaystyle\\sum_{y \\in S}\\dfrac{1}{n}$ (because $H$ is universal and by definition of universal hash function) = $\\dfrac{|S|}{n} = \\alpha = O(1)$\n",
    "    \n",
    "### Open addressing\n",
    "\n",
    "- one object per slot, hash function produces a probe sequence for each possible key $x$\n",
    "- difficult to analyze rigorousely\n",
    "- heuristic assumption: all $n!$ probe sequences equally\n",
    "- claim: under heuristic assumption, expected insertion time is $\\dfrac{1}{1-\\alpha}$, where $\\alpha$ = load\n",
    "- proof\n",
    "    - a random probe finds an empty slot with probability $1-\\alpha$\n",
    "    - thus, insertion time is approximately equals to the number $N$ of coin flips to get \"heads\", where $Pr[$\"heads\"$] = 1-\\alpha$\n",
    "    - note $E[N]$ = (1st coin flip) + (probability of tails)(expected number of further coin flip needed) = $1 + \\alpha E[N]$\n",
    "    - thus $E[N] = \\dfrac{1}{1-\\alpha}$\n",
    "    \n",
    "### Linear probing\n",
    "- heuristic assumption is completely false\n",
    "- assume instead: initial probes uniform at random independent for different keys\n",
    "- theorem: expected insertion time = $\\dfrac{1}{(1-\\alpha)^{2}}$\n",
    "\n",
    "### Bloom filters\n",
    "\n",
    "- fast insert and lookup\n",
    "- compare to hash table\n",
    "    - more space efficient (pro)\n",
    "    - can't store an associated object (con)\n",
    "    - no delete (con)\n",
    "    - small false positive probability (con) \n",
    "        - might say $x$ has been inserted although it hasn't\n",
    "- no false negative (if $x$ was inserted, lookup(x) guaranteed to succeed) \n",
    "- false positive if all $k$ $h_{i}(x)$'s are already set to $1$ by other insertions \n",
    "        \n",
    "Applications\n",
    "- early spellcheckers\n",
    "- list of forbidden passwords\n",
    "- network routers (limited memory, so need to be super fast)\n",
    "\n",
    "Ingredients\n",
    "- array of $n$ bits ($\\dfrac{n}{|S|}$ = number of bits per object in data set $S$)\n",
    "- $k$ hash functions $h_{1} \\dots h_{k}$, where $k$ is a small constant\n",
    "\n",
    "Insert(x)\n",
    "- for $i = 1,2 \\dots k$ (whether or not bit already set to 1)\n",
    "    - set $A[h_{i}(x)] = 1$\n",
    "    \n",
    "Lookup(x)\n",
    "- return True <=> $A[h_{i}(x)] = 1$ for every $i = 1,2 \\dots k$ \n",
    "\n",
    "### Heuristic analysis\n",
    "\n",
    "- intuition: should be a trade-off between space and error (false positive) probability\n",
    "- assume: all $h_{i}(x)$'s uniformly random and independent (across different $i$'s and $x$'s)\n",
    "- setup: $n$ bits, insert data set $S$ into bloom filter\n",
    "- note: for each bit of $A$, the probability it's been set to $1$ is\n",
    "    - $1-(1-\\dfrac{1}{n})^{k|S|} \\le 1 - e^{-k|S|/n} = 1 - e^{-k/b}$, $b$ = number of bits per object $\\dfrac{n}{|S|}$\n",
    "- thus, false positive probability is $\\le [1-e^{-k/b}]^{k} = \\epsilon$ \n",
    "- for fixed $b$, $\\epsilon$ is minimized by setting\n",
    "    - $\\epsilon \\approx \\dfrac{1}{2}^{(ln2)b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read file line by line\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to be read\n",
    "\n",
    "    Returns:\n",
    "    array (list) --  contains numbers in sorted order\n",
    "    \"\"\"\n",
    "\n",
    "    array = []\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array = line.read().split(\"\\n\")\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = int(array[i])\n",
    "        \n",
    "    array.sort()    \n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sum(array, a,b):\n",
    "    \"\"\"\n",
    "    Implement two sum algorithm\n",
    "\n",
    "    Args:\n",
    "    a (integer) - lower bound of a range (inclusive)\n",
    "    b (integer) - upper bound of a range (inclusive)\n",
    "\n",
    "    Returns:\n",
    "    number_of_distinct_two_sum (integer) -- number of distinct x and y such that x + y = t where t is a number between a and b\n",
    "    \"\"\"\n",
    "\n",
    "    low_index = 0\n",
    "    high_index = len(array) - 1\n",
    "    the_sum_set = set()\n",
    "\n",
    "    # traverse towards middle from both ends\n",
    "    while high_index > low_index: \n",
    "        \n",
    "        # if sum is greater than b, reduce bigger number for the next iteration\n",
    "        if array[low_index] + array[high_index] > b: \n",
    "            high_index -= 1\n",
    "            continue\n",
    "            \n",
    "        # if sum is less than a, increase smaller number for the next iteration\n",
    "        if array[low_index] + array[high_index] < a: \n",
    "            low_index += 1\n",
    "            continue\n",
    "            \n",
    "        # if two numbers are not distinct, no need to check further\n",
    "        if array[low_index] == array[high_index]: \n",
    "            break\n",
    "\n",
    "        the_low_index = low_index\n",
    "\n",
    "        # find the sum of two numbers at the current indices\n",
    "        the_sum = array[the_low_index] + array[high_index] \n",
    "\n",
    "        # if a <= \"the_sum\" <= b, there is a hit\n",
    "        while the_sum >= a and the_sum <= b and high_index > the_low_index: \n",
    "            the_sum_set.add(the_sum)\n",
    "            the_low_index += 1\n",
    "            \n",
    "            # if two numbers are not distinct, no need to check further\n",
    "            if array[low_index] == array[high_index]: \n",
    "                break\n",
    "            the_sum = array[the_low_index] + array[high_index]\n",
    "        high_index -= 1\n",
    "\n",
    "    number_of_distinct_two_sum =len(the_sum_set)\n",
    "    print(number_of_distinct_two_sum)\n",
    "    return number_of_distinct_two_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = open_file(\"data/two-sum.txt\")\n",
    "assert(two_sum(array, -10000, 10000) == 427)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
