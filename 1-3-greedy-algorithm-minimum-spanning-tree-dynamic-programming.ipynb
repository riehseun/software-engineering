{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm, Minimum Spanning Tree, and Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - internet routing\n",
    "\n",
    "- Ex. Stanford gateway router needs to send data to the Cornell gateway router\n",
    "- Djikstra's algorithm does this (with nonnegative edge length)\n",
    "- Issue is that Stanford gateway router would need to know entire Internet\n",
    "- Need a shortest-path algorithm that uses only local computation\n",
    "- Solution is Bellman-Ford algorithm (also handles negative edge costs)\n",
    "\n",
    "## Application - sequence alignment\n",
    "\n",
    "- Input: two strings over the alphabet {A,C,G,T}\n",
    "- Problem: figure out how similar the two strings are\n",
    "- Measure similarity via quality of \"best\" alignment\n",
    "    - Penalty $pen_{gap} \\ge 0$ for each gap\n",
    "    - Lenalty $pen_{AT} \\ge 0$ for mismatching A and T\n",
    "    - Etc\n",
    "- Output: alignment of the strings that minimizes the total penalty (Needleman-Wunsch score)\n",
    "- Solution: straightforward dynamic programming\n",
    "\n",
    "## Greedy algorithm\n",
    "\n",
    "- Ex. Dijkstra's shortest path algorithm\n",
    "- Easy to propose\n",
    "- Easy runtime analysis\n",
    "- Hard to eatablish correctness\n",
    "- Most greedy algorithms are not correct\n",
    "\n",
    "## Application - optimal caching\n",
    "\n",
    "- Cache is faster than memory\n",
    "- On a fault (cache miss), need to evict something from cache to make room\n",
    "- Theorem: the \"furthest-in-future\" algorithm is optimal (minimizes the number of cache misses)\n",
    "- Serves as guideline for practical algorithm (\"Least Recently Used\" should do well provided data exhibits locality of reference)\n",
    "- Serves as idealized benchmark for caching algorithms\n",
    "\n",
    "## Application - scheduling\n",
    "\n",
    "- Setup\n",
    "    - One shared resource(ex. a processor)\n",
    "    - Many \"jobs\" to do (ex. processes)\n",
    "- Question\n",
    "    - In what order should we sequence the jobs?\n",
    "- Assume: each job has a \n",
    "    - Weight $w_{j}$ (\"priority\")\n",
    "    - Length $l_{j}$\n",
    "- Definition: the completion time $c_{j}$ of job $j$ = sum of job lengths up to and including $j$\n",
    "- Goal: minimizes the weighted sum of completion times $min \\displaystyle\\sum_{j=1}^{n}w_{j}c_{j}$\n",
    "- Intuition\n",
    "    - With equal lengths, schedule larger or smaller weight jobs earlier? larger\n",
    "    - With equal weights, schedule shorter or longer jobs earlier? shorter\n",
    "- What if $w_{i} \\gt w_{j}$ but $l_{i} \\gt l_{j}$?\n",
    "    - Assign \"scores\" to jobs that are\n",
    "        - Increasing in weight\n",
    "        - Decreasing in length\n",
    "- Guess #1: order jobs by decreasing value of $w_{j} - l_{j}$ (not always correct)\n",
    "- Guess #2: order jobs by decreasing raio $\\dfrac{w_{j}}{l_{j}}$ (always correct, runs in $O(nlogn)$ - just need to sort)\n",
    "\n",
    "### claim - guess #2 is alway correct\n",
    "\n",
    "- By an exchange argument\n",
    "- Fix arbitrary input of $n$ jobs\n",
    "- Consider proof by contradiction\n",
    "- Let $\\sigma$ = greedy schedule, $\\sigma*$ = optimal schedule (with $\\sigma*$ better than $\\sigma$)\n",
    "- Assume all $\\dfrac{w_{j}}{l_{j}}$'s are distinct\n",
    "- Assume by just renaming jobs $\\dfrac{w_{1}}{l_{1}} \\gt \\dfrac{w_{2}}{l_{2}} \\gt \\dots \\gt \\dfrac{w_{n}}{l_{n}}$\n",
    "- Thus, greedy schedule $\\sigma$ is just $1,2,3 \\dots n$\n",
    "- Thus, if optimal schedule $\\sigma^{*} \\ne \\sigma$, then there are consecutive jobs $i,j$ with $i>j$\n",
    "- Suppose we exchange order of $i,j$ in $\\sigma^{*}$ (leaving other jobs unchanged)\n",
    "    - Cost of exchange is $w_{i}l_{j}$ ($c_{i}$ goes up by $l_{j}$)\n",
    "    - Benefit of exchange is $w_{j}l_{i}$ ($c_{j}$ goes down by $l_{i}$)\n",
    "    - $i \\gt j => \\dfrac{w_{i}}{l_{i}} \\lt \\dfrac{w_{j}}{l_{j}} => \\dfrac{w_{i}}{l_{j}} \\lt \\dfrac{w_{j}}{l_{i}}$\n",
    "        - cost $\\lt$ benefit, meaning swap improves $\\sigma^{*}$, contradicts optimality of $\\sigma^{*}$ \n",
    "        \n",
    "### claim - guess #2 is correct even with ties\n",
    "\n",
    "- Fix arbitrary input of $n$ jobs\n",
    "- Let $\\sigma$ = greedy schedule, $\\sigma^{*}$ = any other schedule\n",
    "- Will show $\\sigma$ at least as good as $\\sigma^{*}$\n",
    "    - Implies that greedy schedule is optimal\n",
    "- Assume by just renaming jobs, greedy schedule $\\sigma$ is just $1,2,3 \\dots n$ (and so $\\dfrac{w_{1}}{l_{1}} \\gt \\dfrac{w_{2}}{l_{2}} \\gt \\dots \\gt \\dfrac{w_{n}}{l_{n}}$)\n",
    "- Consider arbitrary schedule $\\sigma*$. If $\\sigma^{*} = \\sigma$, done\n",
    "- Else recall there exists consecutive jobs $i,j$ in $\\sigma^{*}$ with $i \\gt j$\n",
    "- Exchanging $i$ and $j$ in $\\sigma^{*}$ has net benefit of $w_{j}l_{i}-w_{i}l_{j} \\ge 0$\n",
    "- Exchanging an \"adjacent inversion\" like $i,j$ only makes $\\sigma^{*}$ better, and it decreases the number of inverted pairs (jobs $i,j$ with $i \\gt j$ and $i$ scheduled earlier)\n",
    "- After at most $n\\choose{2}$ such exchanges, can transform $\\sigma^{*}$ into $\\sigma$\n",
    "- $\\sigma$ at least as good as $\\sigma^{*}$\n",
    "- Greedy is optimal\n",
    "\n",
    "## Minimum spanning trees\n",
    "\n",
    "- Input: \"undirected\" graph\" $G=(V,E)$ and a cost (for each edge $e \\in E$)\n",
    "    - Assume adjacency list representation \n",
    "    - OK if edge cost are negative\n",
    "- Output: minimum cost tree $T \\subseteq E$ that spans all vertices \n",
    "    - $T$ has no cycles\n",
    "    - Subgraph $(U,T)$ is connected\n",
    "- Assumption #1: input graph $G$ is connected\n",
    "    - Else no spanning trees\n",
    "    - Easy to check in preprocessing (ex. depth-first search)\n",
    "- Assumption #2: edge costs are distinct\n",
    "    - Prim + Kruskal remain correct with ties (which can be broken arbitrarily)\n",
    "    \n",
    "## Prim's MST algorithm\n",
    "\n",
    "- Runs in $O(mn)$\n",
    "- Initialize $X = \\{s\\}$ # $s \\in V$ chosen arbitrary\n",
    "- T = empty set # invariant: $X$ = vertices spanned by tree-so-far $T$\n",
    "- While $X \\ne V$ # increases the number of spanned vertices in cheapest way possible\n",
    "    - Let edge$(u,v)$ be the cheapest edge with $u \\in X$ and $v \\notin X$\n",
    "    - Add $e$ to $T$\n",
    "    - Add $v$ to $X$\n",
    "    \n",
    "### claim - Prim's algorithm outputs a spanning tree\n",
    "\n",
    "- Definition: a cut of a graph $G = (V,E)$ is a partition of $V$ into 2 non-empty sets\n",
    "- Empty cut lemma\n",
    "    - A graph is not connected <=> there exists a cut$(A,B)$ with no crossing edges\n",
    "    - Proof: (<=)\n",
    "        - Assume RHS\n",
    "        - Pick any $u \\in A$ and $v \\in B$\n",
    "        - Since no edges cross $(A,B)$, there is no $u,v$ path in $G$ \n",
    "        - Thus, $G$ not connected\n",
    "    - Proof: (=>)\n",
    "        - Suppose $G$ has no $u,v$ path\n",
    "        - Define $A$ = {vertices reachable from $u$ in $G$} ($u$'s connected component)\n",
    "        - Define $B$ = {all other vertices} (all other connected components)\n",
    "        - Note: no edges cross out $(A,B)$ (otherwise $A$ would be bigger!)\n",
    "- Double-crossing lemma\n",
    "    - Suppose the cycle $C \\subseteq E$ has an edge crossign the cut$(A,B)$, then so does some other edge of $C$\n",
    "- Lonely cut corollary\n",
    "    - If $e$ is the only edge crossing some cut$(A,B)$, then it is not in any cycle (if it were in a cycle, some other edge would have to cross the cut!)\n",
    "- In summary\n",
    "    - (1) Algorithm maintains invariant that $T$ spans $X$\n",
    "    - (2) Can't get stuck with $X \\ne V$ (otherwise the cut $(X, V-X)$ must be empty - by empty cut lemma, input graph $G$ is disconnected)\n",
    "    - (3) No cycles ever get created in $T$\n",
    "        - Consider any iteration with current sets $X$ and $T$\n",
    "        - Suppose $e$ gets added\n",
    "        - $e$ is the first edge crossing $(X, V-X)$ that gets added to $T$ => its addition can't create a cycle in $T$ (by lonely cut corollary)\n",
    "        \n",
    "### claim - Prim's algorithm always outputs a minimum-cost spanning tree\n",
    "\n",
    "- Cut property: consider an edge $e$ of $G$. suppose there is a cut $(A,B)$ such that $e$ is the cheapest edge of $G$ that crosses it. then $e$ belongs to the MST of $G$\n",
    "- Claim: cut property => Prim's algorithm is correct\n",
    "    - Already proved Prim's algorithm outputs a spanning tree $T^{*}$\n",
    "    - Key point: every edge $e \\in T^{*}$ is explicitly justified by the cut property\n",
    "        - $T^{*}$ is a subset of the MST\n",
    "        - Since $T^{*}$ is already a spanning tree, it must be the MST\n",
    "- Proof of cut property\n",
    "    - Suppose there is an edge $e$ that is the cheapest one crossing a cut$(A,B)$, yet $e$ is not in the MST $T^{*}$\n",
    "    - Idea: exchange $e$ with another edge in $T^{*}$ to make it even cheaper (contradiction)\n",
    "    - Since $T^{*}$ is connected, must construct an edge $f (\\ne e)$ crossing $(A,B)$\n",
    "    - Idea: exchange $e$ and $f$ to get a spanning tree cheaper than $T^{*}$ (contradiction)\n",
    "    - Let $C$ = cycle created by adding $e$ to $T^{*}$\n",
    "    - By double-crossing lemma: some other edge $e^{'}$ of $C$ (with $e^{'} \\ne e$ and $e^{'} \\in T^{*}$) crosses $(A,B)$ \n",
    "    - Note: $T = T^{*}\\cup\\{e\\}-\\{e^{'}\\}$ is also a spanning tree\n",
    "    - Since $C_{e} \\lt C_{e^{'}}$, $T$ is cheaper than purported MST $T^{*}$, contradiction!\n",
    "    \n",
    "## Prim's algorithm with heaps\n",
    "\n",
    "- Invariant #1: elements in heap = vertices of $V-X$\n",
    "- Invariant #2: for $v \\in V-X$, $key[v]$ = cheapest edge $(u,v)$ with $i \\in X$ (or $+\\infty$ if no such edges exist)\n",
    "- Check: can initialize heap with $O(m+nlogn) = O(mlogn)$ preprocessing\n",
    "- Note: given invariants, extract-min yields next vertex $v \\notin X$ and edge $(u,v)$ crossing $(X, V-X)$ to add to $X$ and $T$, respectively\n",
    "- Issue: might need to recognize some keys to maintain invariant #2 after each extract-min\n",
    "\n",
    "When $v$ added to $X$\n",
    "- For each edge $(v,w) \\in E$\n",
    "    - If $w \\in V-X$\n",
    "        - (Update key if needed)\n",
    "        - Delete $w$ from heap\n",
    "        - Recompute $key[w] = min[key[w], c_{vw}]$\n",
    "        - Re-insert into heap\n",
    "        \n",
    "Running time with heaps\n",
    "- Dominated by time required for heap operations\n",
    "- $(n-1)$ inserts during preprocessing\n",
    "- $(n-1)$ extract-mins (one per iteration of while loop)\n",
    "- Each edge $(v,w)$ triggers one delete/insert combo (when its first endpoint is sucked into $X$)\n",
    "- $O(m)$ heap operations (recall $m \\ge n-1$ since $G$ connected)\n",
    "- $O(mlogn)$ time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "    \n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "    \n",
    "    Returns:\n",
    "    tuple_data (tuple of list and integer) -- adjancency representation of graph and number of nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "    \n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0]) \n",
    "        del array_of_array[0] # delete first element, which is just the length of data\n",
    "        for array in array_of_array:\n",
    "            subarray = array.split(\" \")\n",
    "            node1 = int(subarray[0])\n",
    "            node2 = int(subarray[1])\n",
    "            cost = int(subarray[2])\n",
    "            data_array.append((node1, node2, cost))\n",
    "            \n",
    "    tuple_data = (data_array, num_nodes)\n",
    "    return tuple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(array, X, T):\n",
    "    \"\"\"\n",
    "    For all node1 in X, find node2 that is not in X, that makes the cheapest edge between node1 and node2\n",
    "    \n",
    "    Args:\n",
    "    array (list) -- adjancency representation of graph\n",
    "    X (list) -- stores all vertices that consist minimun spanning tree\n",
    "    T (list) -- stores all costs of edges that consist minimun spanning tree\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    minimum_cost = 1000000\n",
    "    minimum_node1 = 0\n",
    "    minimum_node2 = 0\n",
    "    for node1 in X:\n",
    "        for node2 in get_connected_node(node1, array):\n",
    "            if node2 not in X:\n",
    "                cost = get_cost(node1, node2, array)\n",
    "                if cost < minimum_cost:\n",
    "                    minimum_node1 = node1\n",
    "                    minimum_node2 = node2\n",
    "                    minimum_cost = cost\n",
    "    \n",
    "    X.append(minimum_node2)\n",
    "    T.append(minimum_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_node(node1, array):\n",
    "    \"\"\"\n",
    "    Find all nodes that are connected by an edge for node1\n",
    "    \n",
    "    Args:\n",
    "    node1 (integer) -- input node\n",
    "    array (list) -- adjancency representation of graph\n",
    "    \n",
    "    Returns:\n",
    "    nodes (list) - all nodes connected to node1\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = []\n",
    "    \n",
    "    for item in array:\n",
    "        if item[0] == node1:\n",
    "            nodes.append(item[1])\n",
    "        elif item[1] == node1:\n",
    "            nodes.append(item[0])\n",
    "            \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(node1, node2, array):\n",
    "    \"\"\"\n",
    "    Find cost of edge between node1 and node2\n",
    "    \n",
    "    Args:\n",
    "    node1 (integer) -- first node of an edge\n",
    "    node2 (integer) -- second node of an edge\n",
    "    array (list) -- adjancency representation of graph\n",
    "    \n",
    "    Returns:\n",
    "    cost (integer) -- cost of edge between node1 and node2\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = 0\n",
    "    \n",
    "    for item in array:\n",
    "        if item[0] == node1 and item[1] == node2:\n",
    "            cost = item[2]\n",
    "        if item[0] == node2 and item[1] == node1:\n",
    "            cost = item[2]\n",
    "            \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prim(file_path):\n",
    "    \"\"\"\n",
    "    Implements Prim's MST algorithm\n",
    "    \n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "    \n",
    "    Returns:\n",
    "    cost (integer) -- cost of minimum spanning tree\n",
    "    \"\"\"\n",
    "    \n",
    "    tuple_obj = open_file(file_path)\n",
    "    array = tuple_obj[0]\n",
    "    num_nodes = tuple_obj[1]\n",
    "    \n",
    "    X = [] # store explored nodes\n",
    "    s = array[0][0] # pick random node\n",
    "    X.append(s)\n",
    "    \n",
    "    T = [] # store costs\n",
    "    T.append(0)\n",
    "    \n",
    "    while len(X) < num_nodes:\n",
    "        greedy_search(array, X, T)\n",
    "    \n",
    "    cost = sum(T)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(prim(\"data/1-3-1-edge.txt\") == -3612829)\n",
    "assert(prim(\"data/1-3-1-edge1.txt\") == 7)\n",
    "assert(prim(\"data/1-3-1-edge2.txt\") == 15)\n",
    "assert(prim(\"data/1-3-1-edge3.txt\") == 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MST review\n",
    "\n",
    "- Input: undirected graph $G = (V,E)$, edge cost $c_{e}$\n",
    "- Output: min-cost spanning tree (no cycles, connected)\n",
    "- Assumptions: $G$ is connected, distinct edge costs\n",
    "- Cut property: if $e$ is the cheapest edge crossing some cut$(A,B)$, then $e$ belongs to the MST\n",
    "\n",
    "\n",
    "## Kruskal's MST Algorithm \n",
    "\n",
    "- $O(mn)$\n",
    "- Sort edges in order of increasing cost (rename edges 1,2,3,... so that $c_{1} < c_{2} < \\dots < c_{m}$)\n",
    "- Let $T$ = empty set\n",
    "- For $i=1 \\dots m$ # $O(m)$\n",
    "    - If $T\\cup\\{i\\}$ has no cycles\n",
    "        - Add $i$ to $T$ # $O(n)$ use BFS/DFS in the graph $(V,T)$ which contains $\\le n-1$ edges  \n",
    "- Return $T$\n",
    "\n",
    "### correctness\n",
    "\n",
    "- Let $T^{*}$ = output of Kruskal's algorithm on input graph $G$\n",
    "- Clearly $T^{*}$ has no cycles\n",
    "- $T^{*}$ is connected\n",
    "    - By empty cut lemma, only need to show that $T^{*}$ crosses every cut\n",
    "    - Fix a cut$(A,B)$, since $G$ connected at least one of its edges cross $(A,B)$\n",
    "- Key point: Kruskal will include first edge crossing $(A,B)$ that it sees (by lonely cut corollary, cannot create a cycle)\n",
    "- Every edge of $T^{*}$ satisfied by the cut property (implies $T^{*}$ is the MST)\n",
    "    - Consider iteration where edge $(u,v)$ added to current set $T$. since $T\\cup\\{(u,v)\\}$ has no cycle, $T$ has no $u-v$ path\n",
    "        - There exists an empty cut$(A,B)$ separating $u$ and $v$ (as in proof of empty cut lemma)\n",
    "        - No edges crossing $(A,B)$ were previsouly considered by Kruskal's algorithm\n",
    "        - $(u,v)$ is the first (hence the cheapest!) edge crossing $(A,B)$\n",
    "        - $(u,v)$ justified by the cut property\n",
    "\n",
    "## Union-Find data structure\n",
    "\n",
    "- Maintain partition of a set of objects\n",
    "- Find$(x)$: return name of group that $x$ belongs to\n",
    "- Union$(c_{i},c_{j})$: fuse groups $c_{i},c_{j}$ into a single one\n",
    "\n",
    "### why usefu for Kruskal's?\n",
    "\n",
    "- Objects = vertoces\n",
    "- Groups = connected components w.r.t. chosen edges $T$\n",
    "- Adding new edge $(u,v)$ to $T$ <=> fusing connected components of $u,v$\n",
    "\n",
    "### Union-Find basics\n",
    "\n",
    "- Motivation: $O(1)$ time cycle checks in Kruskal's algorithm\n",
    "- Idea #1: maintain one linked structure per connected component of $(V,T)$\n",
    "    - Each component has an arbitrary leader vertex\n",
    "- Invariant: each vertex points to the leader of its component (\"name\" of a component inherited from leader vertex)\n",
    "- Key point: given edge$(u,v)$, can check if $u$ and $v$ already in same component in $O(1)$ time (iff leader pointers of $u$ and $v$ match <=> Find$(u)$ = Find$(v)$ => $O(1)$ time cycle checks!)\n",
    "- Note: when new edge $(u,v)$ added to $T$, connected components of $u$ and $v$ merge\n",
    "- How many times does a single vertex $v$ have its leader pointer updated over the course of Kruskal's algorithm?\n",
    "    - $O(logn)$ because every time $v$'s leader gets updated, population of its component at least doubles => can only happen $\\le log_{2}^n$ time\n",
    "\n",
    "### Running time\n",
    "\n",
    "- $O(mlogn)$ for sorting\n",
    "- $O(m)$ for cycle checks ($O(1)$ per iteration)\n",
    "- $O(nlogn)$ overall for leader pointer updates\n",
    "- $O(mlogn)$ total, matching Prim's\n",
    "\n",
    "### State-of-the-art MST\n",
    "\n",
    "- $O(m)$ randomized algorithm (Karger-Klein-Tarjan JACM 1995)\n",
    "- $O(m\\alpha(n))$ deterministic (Chazelle JACM 2000)\n",
    "    - \"ïnverse Ackerman function\": grows much slower than $log^{*}n$\n",
    "\n",
    "## Clustering\n",
    "\n",
    "- \"unsupervised learning\"\n",
    "- Informal goal: given $n$ points, classify into \"coherent groups\"\n",
    "- Assumptions\n",
    "    - As input, given a (dis)similarity measure - a distance $d(p,g)$ between each point pair\n",
    "    - Symmetric (ex. $d(p,g) = d(g,p)$)\n",
    "- Ex. Euclidean distance, genome similarity, etc\n",
    "\n",
    "### Max-spacing k-clusterings\n",
    "\n",
    "- Assume: we know $k$ = number of clusters desired (in practice, can experiment with a range of values)\n",
    "- Call pointers $p,q$ separated if they are assigned to different clusters\n",
    "- Definition: the spacing of a $k$-clustering in $min_{separated\\ p,q}d(p,q)$ (bigger the better)\n",
    "- Problem: given a distance measure $d$ and $k$, compute the $k$-clustering with maximum spacing\n",
    "\n",
    "### A greedy algorithm\n",
    "\n",
    "- Initially, each point in a separate cluster\n",
    "- Repeat until only $k$ clusters\n",
    "    - Let $p,q$ = closest paif of separate points (determines the current spacing)\n",
    "    - Merge the cluster containing $p$ and $q$ into a single cluster\n",
    "- Just like Kruskal's MST, but stopped early (single-link clustering)\n",
    "    - Points <=> vertices\n",
    "    - Distances <=> edge costs\n",
    "    - Point pairs <=> edges\n",
    "    \n",
    "### Correctness\n",
    "\n",
    "- Claim: single-link clustering finds the max-spacing $k$-clustering \n",
    "- Proof\n",
    "    - Let $c_{1} \\dots c_{k}$ = greedy clustering with spacing $S$\n",
    "    - Let $\\hat{c_{1}} \\dots \\hat{c_{k}}$ = arbitrary other clustering\n",
    "    - Need to show spacing of $\\hat{c_{1}} \\dots \\hat{c_{k}}$ is $\\le S$\n",
    "    - Case #1: $\\hat{c_{i}}$'s are the same as the $c_{i}$'s (maybe after remaning) => has the same spacing $S$\n",
    "    - Case #2: otherwise, can find a point pair $p,q$ such that \n",
    "        - $p,q$ in the same greedy cluster $c_{i}$\n",
    "        - $p,q$ in different clusters $\\hat{c_{i}},\\hat{c_{j}}$\n",
    "    - Property of greedy algorithm: if two points $x,y$ \"directly merged at some point\", then $d(x,y) \\le S$ (distance between merged point pairs only goes up)\n",
    "    - Easy case: if $p,q$ directly merged at some point, $S \\ge d(p,q) \\ge$ spacing of $\\hat{c_{1}} \\dots \\hat{c_{k}}$\n",
    "    - Tricky case: $p,q$ \"indirectly merged\" through multiple direct merges\n",
    "        - Let $p,a_{1} \\dots a_{l},q$ be the path of direct greedy merges connecting $p$ and $q$\n",
    "        - Key point: since $p \\in \\hat{c_{i}}$ and $q \\notin \\hat{c_{i}}$, $\\exists$consecutive pair $a_{j}, a_{j+1}$ with $a_{j} \\in \\hat{c_{i}}, a_{j+1} \\notin \\hat{c_{i}}$ => $s \\ge d(a_{j}, a_{j+1}) \\ge$ spacing of $\\hat{c_{1}} \\dots \\hat{c_{k}}$\n",
    "        \n",
    "## Advanced Union-Find\n",
    "\n",
    "### Previous solution (for Kruskal's MST)\n",
    "\n",
    "- Each $x \\in X$ points directly to the \"leader\" of its group\n",
    "- $O(1)$ Find (just return $x$'s leader)\n",
    "- $O(nlogn)$ total works for $n$ Unions (when 2 groups merge, smaller group inherits leader of larger one)\n",
    "\n",
    "### Lazy Union\n",
    "\n",
    "- New idea: update only one pointer each merge!\n",
    "- In general: when two groups merge in a Union, make one group's leader (ex. root of the tree) a child of the other one\n",
    "- Pro: Union reduces to 2 Finds ($r_{1}$ = Find$(x)$, $r_{2}$ = Find$(y)$) and $O(1)$ extra work (link $r_{1}, r_{2}$ together)\n",
    "- Con: to recover leader of an object, need to follow a pth of parent pointers (not just one!) => not clear if Find still takes $O(1)$\n",
    "- New implementation: each object $x \\in X$ has a parent field \n",
    "- Invariant: parent pointers induce a collection of directed trees on $x$ ($x$ is root <=> parent$[x] = x$)\n",
    "- Initially: for all $x$, parent$[x] = x$\n",
    "- Find$(x)$: traverse parent pointers from $x$ until you hit the root\n",
    "- Union$(x,y)$: $s_{1}$ = Find$(x)$; $s_{2}$ = Find$(y)$. reset parent of one of $s_{1}, s_{2}$ to be the other\n",
    "\n",
    "### Union by rank\n",
    "\n",
    "- For each $x \\in X$, maintain field rank$[x]$ (in general rank$[x] = 1 + $(max rank of $x$'s children))\n",
    "- Invariant: for all $x \\in X$, rank$[x]$ - maximum number of hops from some leaf to $x$ (initially, rank$[x] = 0$ for all $x \\in X$)\n",
    "- To avoid scraggly trees, given $x$ and $y$\n",
    "    - $s_{1}$ = Find$(x)$, $s_{2}$ = Find$(y)$\n",
    "    - If rank$[s_{1}]$ $\\gt$ rank$[s_{2}]$, then set parent$[s_{2}]$ to $s_{1}$, else get parent$[s_{1}]$ to $s_{2}$ \n",
    "- Make old root with smaller rank child of the root with the larger rank (choose new root arbitrarily in case of a tie and add $1$ to its rank)    \n",
    "\n",
    "### Properties of rank\n",
    "\n",
    "- Immediate from invariant/rank maintenance\n",
    "    - For all objects $x$, rank$[x]$ only goes up over time\n",
    "    - Only rank of roots can go up (once $x$ a non-root, rank$[x]$ forzen forevermore)\n",
    "    - Ranks strictly increase along a path to the root\n",
    "    \n",
    "### Rank lemma\n",
    "\n",
    "- Consider an arbitrarty sequence of Union (+ Find) operations. For every $r \\in {0,1,2,\\dots}$, there are at most $n/2^{r}$ objects with rank $r$\n",
    "- Corollary: max rank always $\\le log_{2}n$\n",
    "- Corollary: worst-case running time of Find, Union is $O(logn)$\n",
    "- Claim: if $x,y$ have the same rank $r$, then their subtrees (objects from which can reach $x,y$) are disjoint\n",
    "- Proof\n",
    "    - Suppose subtrees of $x,y$ have object $z$ in common\n",
    "        - $\\exists$paths $z->x, z->y$\n",
    "        - One of $x,y$ is an ancester of the other\n",
    "        - The ancestor has strictly larger rank\n",
    "- Claim: the subtree of a rank $r$ object has size $\\ge 2^{r}$\n",
    "- Proof\n",
    "    - Rank $r$ => subtree size $\\ge 2^{r}$\n",
    "    - Base case: initialy all ranks $= 0$, all subtree sizes $= 1$\n",
    "    - Inductive step: nothing to prove unless the rank of some object changes (subtree sizes only go up)\n",
    "    - Interesting case: Union$(x,y)$, with $s_{1}=$ Find$(x)$, $s_{2}=$ Find$(y)$, and rank$[s_{1}] =$ rank$[s_{2}] = r$ => $s_{2}$'s new rank $= r+1$ => $s_{2}$'s new subtree size $= s_{2}$'s old subtree size $+ s_{1}$'s old subtree size (each at least $2^{r}$ by the inductive hypothesis) $\\ge 2^{r+1}$ \n",
    "    \n",
    "### Path compression\n",
    "\n",
    "- Idea: why bother traversing a leaf-root path multiple-times? after Find$(x)$, install shortcuts (ex. revise parent pointers) to $x$'s root all along the $x$ => root path\n",
    "- Con: constant-factor overhead to Find (from \"multitasking\")\n",
    "- Pro: speeds up subsequent Finds\n",
    "\n",
    "### On ranks\n",
    "- Important: maintain all rank fields exactly as without path compression\n",
    "    - Rank initially all 0\n",
    "    - In Union, new root = old root with bigger rank\n",
    "    - When merging two nodes of common rank $r$, reset new root's rank to $r+1$\n",
    "- Bad news: now rank$[x]$ is only an upper boud on the maximum number of hops on a path from a leaf to $x$ (which could be much less)\n",
    "- Good news: rank lemma still holds ($\\le n/2^{r}$ objects with rank $r$) still always have rank$[$parent$[x]]$ > rank$[x]$ for all non-roots $x$\n",
    "\n",
    "### Hopcroft-Ullman theorem\n",
    "\n",
    "- With union by rank and path compression, $m$ Union + Find operations take $O(mlog^{*}n)$ time, where $log^{*}n$ = the number of times you need to apply $log$ to $n$ before the result is $\\le 1$\n",
    "\n",
    "### Measuring progress\n",
    "\n",
    "- Initution: installing shortcuts should significantly speed up subsequent Finds + Unions\n",
    "- Question: how to track this progress and quantify the benefit? \n",
    "- Idea: consider a non-root object $x$\n",
    "    - Progress measre: rank$[$parent$[x]]$ - rank$[x]$\n",
    "- Path compression increases this progress measure: if $x$ has old parent $p$, new parent $p' \\ne p$, then rank$[p^{'}] \\gt$rank$[p]$\n",
    "\n",
    "### Proof setup\n",
    "\n",
    "- Rank blocks: $\\{0\\},\\{1\\},\\{2,3,4\\},\\{5 \\dots 2^{4}\\},\\{17,18 \\dots 2^{16}\\},\\{65537 \\dots 2^{65536}\\} \\dots \\{\\dots n\\}$\n",
    "- Note: there are $O(log^{*}n)$ different rank blocks\n",
    "- Semantics: traversal $x$ -> parent$(x)$ is \"fast progress\" <=> rank$[$parent$[x]]$ is larger block than rank$[x]$\n",
    "- Definition: at a given point in time, call object $x$ \"good\" if \n",
    "    - $x$ or $x$'s parent is a root OR\n",
    "    - Rank[parent$[x]$] in larger block than rank$[x]$\n",
    "    \n",
    "### Proof of Hopcroft-Ullman\n",
    "\n",
    "- Point: every Find visits only $O(log^{*}n)$ good nodes $(2 + $number of rank blocks = $O(log^{*}n)$ $)$\n",
    "- Upshot: total work done during $m$ operations = $O(mlog^{*}n)$ (visits to good objects) + total number of visits to bad nodes (need to bound globally by separate argument)\n",
    "- Consider: a rank block $\\{k+1, k+1 \\dots 2^{k}\\}$\n",
    "- Note: when a bad node is visited, its parent is changed to one with strictly larger rank => can only happen $2^{k}$ times before $x$ becomes good (forevermore)\n",
    "- Rank lemma: total number of objects $x$ with final rank in this rank block is $\\displaystyle\\sum_{i=k+1}^{2^{k}}n/2^{i} \\le n/2^{k}$\n",
    "- Recall: only $O(log^{*}n)$ rank blocks\n",
    "- Total work: $O((m+n)log^{*}n)$\n",
    "\n",
    "### Tarjan's bound\n",
    "\n",
    "- Theorem: with union by rank and path compression, $m$ Union + Find operations take $O(m\\alpha(n))$ time, where $\\alpha(n)$ is the inverse Ackerman function\n",
    "\n",
    "### Ackerman function\n",
    "\n",
    "- Define $A_{k}(r)$ for all integers $k$ and $r \\ge 1$ (recursively)\n",
    "- Base case: $A_{0}(r) = r+1$ for all $r \\ge 1$\n",
    "- In general, for $k,r \\ge 1$\n",
    "    - $A_{k}(r)$ = apply $A_{k-1}(r)$ times to $r = (A_{k-1} \\circ A_{k-1} \\circ \\dots \\circ A_{k-1})(r)$\n",
    "    \n",
    "### Inverse Ackerman function\n",
    "\n",
    "- Definition: for every $n \\ge 4, \\alpha(n)$ = minimum value of $k$ such that $A_{k}(2) \\ge n$\n",
    "\n",
    "### Building blocks of Hopcroft-Ullman analysis\n",
    "\n",
    "- Block #1: rank lemma (at most $n/2^{r}$ objects of rank $r$)\n",
    "- Block #2: path compression => If $x$'s parent pointer updated from $p$ to $p'$, then rank$(p')$ $\\ge$ rank$(p)+1$\n",
    "- New idea: stronger version of building block #2. in most cases, rank of new parent much bigger than rank of old parent (not just by 1)\n",
    "\n",
    "### Quantifying rank gaps\n",
    "\n",
    "- Definition: consider a non-root object $x$ (so rank$[x]$ fixed forevermore)\n",
    "- Define: $\\delta(x)$ = max value of $k$ such that rank$[$parent$[x]] \\ge A_{k}($rank$[x])$ \n",
    "- Ex. always have $\\delta(x) \\ge 0$\n",
    "    - $\\delta(x) \\ge 1$ <=> rank$[$parent$[x]] \\ge 2$rank$[x]$\n",
    "    - $\\delta(x) \\ge 2$ <=> rank$[$parent$[x]] \\ge $rank$[x]2^{rank[x]}$\n",
    "for all objects $x$ with rank$[x] \\ge 2$, then $\\delta(x) \\le \\alpha(n)$ (since $A_{\\alpha(n)}(2) \\le n$) \n",
    "\n",
    "### Bad objects\n",
    "\n",
    "- Definition: an object is bad if all of the following holds\n",
    "    - $x$ is not a root\n",
    "    - Parent$(x)$ is not a root\n",
    "    - Rank$(2) \\ge 2$\n",
    "    - $x$ has an ancestor $y$ with $\\delta(y) = \\delta(x)$\n",
    "    \n",
    "### Proof of Tarjan's bound\n",
    "\n",
    "- Upshot: total work of $m$ operations = $O(m\\alpha(n))$ (visits to good objects) + total number of visits to bad objects (will show is $O(n\\alpha(n))$)\n",
    "- Main argument: suppose a Find operation visits a bad object $x$\n",
    "- Path compression: $x$'s new parent will be $p^{'}$ or even higher\n",
    "    - Rank$[x$'s new parent$] \\ge$ rank$[p^{'}] \\ge A_{k}($rank$[y]) \\ge A_{k}($rank$[p])$ \n",
    "- Point: path compression (at least) applies the $A_{k}$ function to rank$[x$'s parent$]$\n",
    "- Consequence: if $r = $rank$[x] (\\ge 2)$, then after $r$ such pointer updates we have \n",
    "    - Rank$[x$'s parent$] \\ge (A_{k} \\circ \\dots r$ times $ \\dots \\circ A_{k})(r) = A_{k+1}(r)$\n",
    "- Thus, while $x$ is bad, every $r$ vistis increases $\\delta(x)$\n",
    "    - $\\le r\\alpha(n)$ visits to $x$ while it's bad\n",
    "- Total number of visits to bad objects $\\le \\displaystyle\\sum_{objects\\ x}$ rank$[x]\\alpha(n) = \\alpha(n)\\displaystyle\\sum_{r \\ge 0}r$ (number of objects with rank $r$) = $n\\alpha(n)\\displaystyle\\sum_{r \\ge 0} r/2^{r} = O(n\\alpha(n))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    tuple_date (tuple) -- an array that holds data and an integer representing size of data\n",
    "    \"\"\"\n",
    "\n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0])\n",
    "        del array_of_array[0] # delete first element, which is just the length of data\n",
    "        for array in array_of_array:\n",
    "            subarray = array.split(\" \")\n",
    "            node1 = int(subarray[0])\n",
    "            node2 = int(subarray[1])\n",
    "            cost = int(subarray[2])\n",
    "            data_array.append((node1, node2, cost))\n",
    "            \n",
    "    tuple_date = (data_array, num_nodes)\n",
    "    return tuple_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_pair_and_merge(sorted_array, T):\n",
    "    \"\"\"\n",
    "    Find two nodes that are in different clusters, and merge them into a single cluster\n",
    "\n",
    "    Args:\n",
    "    sorted_array (list) -- holds tuple that is sorted by its thrid element (which is cost between two nodes)\n",
    "    T (list of list) -- contains \"clusters\"\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    node1 = sorted_array[0][0]\n",
    "    node2 = sorted_array[0][1]\n",
    "    cost = sorted_array[0][2]\n",
    "\n",
    "    index_of_cluster_to_expand = find_cluster(node1, T)\n",
    "    index_of_cluster_to_remove = find_cluster(node2, T)\n",
    "\n",
    "    if index_of_cluster_to_expand != index_of_cluster_to_remove: # if two nodes are already in the same cluster, no need to perform merge on T\n",
    "        for node in T[index_of_cluster_to_remove]:\n",
    "            T[index_of_cluster_to_expand].append(node) # add all nodes in the cluster where node2 belongs to node1's cluster\n",
    "        del T[index_of_cluster_to_remove] # remove node2's cluster\n",
    "        del sorted_array[0] # remove current tuple\n",
    "    else:\n",
    "        del sorted_array[0] # remove current tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(node, T):\n",
    "    \"\"\"\n",
    "    Find a list inside T that the node belongs to\n",
    "\n",
    "    Args:\n",
    "    node (integer) -- represents a node in a graph\n",
    "    T (list of list) -- contains \"clusters\"\n",
    "\n",
    "    Returns:\n",
    "    i (integer) -- index of cluster of T\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(T)):\n",
    "        if node in T[i]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_spacing(T, sorted_array):\n",
    "    \"\"\"\n",
    "    Return the minimum distance between two nodes that are in different clusters\n",
    "\n",
    "    Args:\n",
    "    sorted_array (list) -- holds tuple that is sorted by its thrid element (which is cost between two nodes)\n",
    "    T (list of list) -- contains \"clusters\"\n",
    "\n",
    "    Returns:\n",
    "    min_cost (integer) -- the minimum cost\n",
    "    \"\"\"\n",
    "\n",
    "    for item in sorted_array:\n",
    "        cluster_of_node1 = find_cluster(item[0], T)\n",
    "        cluster_of_node2 = find_cluster(item[1], T)\n",
    "        if cluster_of_node1 != cluster_of_node2:\n",
    "            min_cost = item[2]\n",
    "            return min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(file_path):\n",
    "    \"\"\"\n",
    "    Implements clustering algorithm\n",
    "    \n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "    \n",
    "    Returns:\n",
    "    max_spacing (integer) -- maximum distance between elements in different clusters\n",
    "    \"\"\"\n",
    "    \n",
    "    tuple_obj = open_file(file_path)\n",
    "    \n",
    "    array = tuple_obj[0]\n",
    "    sorted_array = sorted(array, key=lambda x: (x[2])) # sort by third element\n",
    "    num_nodes = tuple_obj[1]\n",
    "    \n",
    "    T = []\n",
    "    for node in range(1, num_nodes+1):\n",
    "        T.append([node])\n",
    "\n",
    "    while len(T) > 4 and len(sorted_array) > 0:\n",
    "        find_closest_pair_and_merge(sorted_array, T)\n",
    "\n",
    "    max_spacing = get_max_spacing(T, sorted_array)\n",
    "    return max_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(clustering(\"data/1-3-2-clustering.txt\") == 106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils.union_find import UnionFind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows with weight and length, and compute difference and ratio\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    data_array -- an array of tuples representing a graph\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0])\n",
    "        num_bits = int(array_of_array[0].split(\" \")[1])\n",
    "        del array_of_array[0] # delete first element, which is just metadata\n",
    "        for i in range(0, len(array_of_array)):\n",
    "            number = int(array_of_array[i].replace(\" \", \"\"))\n",
    "            data_array.append(number)\n",
    "            if number not in data_dict:\n",
    "                data_dict[number] = set()\n",
    "            data_dict[number].add(i+1)\n",
    "                  \n",
    "    return (data_array, data_dict, num_nodes, num_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_base_10_to_2(array):\n",
    "    \"\"\"\n",
    "    Convert a list of integers (base 10) to a list of integers (base 2)\n",
    "    \n",
    "    Args:\n",
    "    array - list of integers\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = int(bin(array[i])[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_heming_distance_1(num_bits):\n",
    "    \"\"\"\n",
    "    Produce heming distance of 1\n",
    "    \n",
    "    Args: \n",
    "    num_bits (integer) -- number of bits in binary\n",
    "    \n",
    "    Returns:\n",
    "    heming_distance_1 (list) -- array that hold heming distance of 1\n",
    "    \"\"\"\n",
    "    \n",
    "    heming_distance_1 = [1 << i for i in range(num_bits)]\n",
    "\n",
    "    convert_base_10_to_2(heming_distance_1)\n",
    "    \n",
    "    return heming_distance_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_heming_distance_2(heming_distance_1):\n",
    "    \"\"\"\n",
    "    Produce heming distance of 2\n",
    "    \n",
    "    Args: \n",
    "    heming_distance_1 (list) -- array that hold heming distance of 1\n",
    "    \n",
    "    Returns:\n",
    "    heming_distance_2 (list) -- array that hold heming distance of 2\n",
    "    \"\"\"\n",
    "    \n",
    "    heming_distance_2 = []\n",
    "    for i in range(0, len(heming_distance_1)):\n",
    "        for j in range(0, len(heming_distance_1)):\n",
    "            if j > i:\n",
    "                dist = int(str(heming_distance_1[i]),2) ^ int(str(heming_distance_1[j]),2)\n",
    "                heming_distance_2.append(dist)\n",
    "\n",
    "    convert_base_10_to_2(heming_distance_2)\n",
    "    \n",
    "    return heming_distance_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_big(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows with weight and length, and compute difference and ratio\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    data_array -- an array of tuplesrepresenting a graph\n",
    "    \"\"\"\n",
    "    \n",
    "    tuple_obj = open_file(file_path)\n",
    "    data_array = tuple_obj[0]\n",
    "    data_dict = tuple_obj[1]\n",
    "    num_nodes = tuple_obj[2]\n",
    "    num_bits = tuple_obj[3]\n",
    "\n",
    "    unionFind = UnionFind()\n",
    "\n",
    "    heming_distance_1 = produce_heming_distance_1(num_bits)\n",
    "    heming_distance_2 = produce_heming_distance_2(heming_distance_1)\n",
    "    distances = heming_distance_1 + heming_distance_2 \n",
    "\n",
    "    for distance in distances:\n",
    "        for key1 in data_dict:\n",
    "            key2 = int(str(distance),2) ^ int(str(key1),2)\n",
    "            key2 = int(bin(key2)[2:]) \n",
    "            if key2 in data_dict:\n",
    "                unionFind.union(key1, key2)\n",
    "\n",
    "    pointer_set = set([unionFind[x] for x in data_dict])\n",
    "    num_clusters = len(pointer_set)\n",
    "    \n",
    "    return num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(clustering_big(\"data/1-3-2-clustering-big1.txt\") == 3)\n",
    "assert(clustering_big(\"data/1-3-2-clustering-big2.txt\") == 15)\n",
    "assert(clustering_big(\"data/1-3-2-clustering-big.txt\") == 6118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman Codes\n",
    "\n",
    "### Binary code\n",
    "\n",
    "- Maps each character of an alphabet $\\Sigma$ to binary string. For example\n",
    "- Ex. $\\Sigma$ = a-z variaous punctuation  (size 32 overall, say)\n",
    "- Obvious encoding: use 32 5-bit binary strings to encode this $\\Sigma$\n",
    "- Can we do better? yes, if same characters of $\\Sigma$ are much more frequent than others, using a variable-length code\n",
    "\n",
    "### Prefix-free codes\n",
    "\n",
    "- Problem: with variable length codes, not clear where one character ends + the next one begins\n",
    "- Solution: make sure that for every pair $i,j \\in \\Sigma$, neither of the encodings $f(i),f(j)$ is a prefix of the other\n",
    "- Ex. {0, 10, 110, 111}\n",
    "- Why useful? can give shorter encodings with non-uniform character frequencies\n",
    "\n",
    "### Code as trees\n",
    "\n",
    "- Goal: best binary prefix-gree encoding for a given set of character frequencies\n",
    "- Useful fact: binary codes <-> binary trees\n",
    "- Example: ($\\Sigma = \\{A,B,C,D\\}$)\n",
    "\n",
    "### Prefix-free codes as trees\n",
    "\n",
    "- In general, left child edges get \"0\" and right child edges get \"1\"\n",
    "- For each $i \\in \\Sigma$, there is exactly one node labelled \"$i$\"\n",
    "- Encoding: bits along path from root to node $i$\n",
    "- Decoding: repeatedly follow path from root until hitting a leaf (ex. 0110111 <-> ACD)\n",
    "- Encoding length of $i$ = depth of $i$ in a tree\n",
    "\n",
    "### Problem definition\n",
    "\n",
    "- Given probability $p_{i}$ for each character $i$, find Tree $T$ that minimize the length of encoding defined by\n",
    "\n",
    "$L(T) = \\displaystyle\\sum_{i}P_{i}$(depth of $i$ in T)\n",
    "\n",
    "Idea #1\n",
    "- Top-down / divide and conquer\n",
    "- Partition $\\Sigma$ into $\\Sigma_{1},\\Sigma_{2}$ each with ~50% of total frequency\n",
    "- Recursively compute $T_{1}$ for $\\Sigma_{1}$, $T_{2}$ for $\\Sigma_{2}$\n",
    "- This is sub-optimal\n",
    "\n",
    "Idea #2 \n",
    "- Build the tree bottom up using successive mergers\n",
    "\n",
    "### A greedy approach\n",
    "\n",
    "- Question: which pair of symbols is \"safe\" to merge?\n",
    "- Observation: final encoding length of $i \\in \\Sigma$ = number of mergers its subtree endures (each merger increases encoding length of participating symbols by 1)\n",
    "- Greedy heuristic: in first iteration, merge the two symbols with the smallest frequencies\n",
    "\n",
    "### Huffman's algorithem\n",
    "\n",
    "- (Given frequencies $p_{i}$ as input)\n",
    "- If len(set) = $|\\Sigma|$ = 2, return\n",
    "- Let $a$,$b \\in \\Sigma$ have the smallest frequencies\n",
    "- Let new_set = $\\Sigma^{'}$ = set with $a$, $b$ replaced by $ab$\n",
    "- Define $p_{ab} = p_{a} + p_{b}$ \n",
    "- Recursively compute $T^{'}$ (for new_set $\\Sigma^{'}$)\n",
    "- Extend $T^{'}$ to $T$ by splitting leaf $ab$ into two leave $a$ & $b$\n",
    "- Return $T$\n",
    "\n",
    "### Correctness\n",
    "\n",
    "- By induction on $n = |\\Sigma|$ (can assume $n \\ge 2$)\n",
    "- Base case: when $n = 2$, algorithm outpus the optimal tree (needs 1 bit per symbol)\n",
    "- Inductive step: fix input with $n = |\\Sigma| \\gt 2$\n",
    "- By inductive hypothesis: algorithm solves smaller subproblems (for $\\Sigma^{'}$ optimally)\n",
    "\n",
    "### Inductive step\n",
    "\n",
    "- Let $\\Sigma^{'} = \\Sigma$ with $a,b$ (symbols with smallest frequencies) replaced by meta-symbol $ab$\n",
    "- Define $p_{ab} = p_{a} + p_{b}$\n",
    "- For $T^{'}$ and $T, L(T)-L(T^{'}) = p_{a}(d+1) + p_{b}(d+1) - (p_{a} + p_{b})d = p_{a} + p_{b}$ (independent of $T,T^{'}$) \n",
    "- Let $X_{ab}$ = trees for $\\Sigma$ that have $a,b$ as siblings\n",
    "\n",
    "### Summarizing\n",
    "\n",
    "- Inductive hypothesis: Huffman's algorithm computes a tree $\\hat{T^{'}}$ that minimizes $L(T^{'})$ for $\\Sigma^{'}$\n",
    "- Upshot: corresponding tree $\\hat{T^{'}}$ minimizes $L(T)$ for $\\Sigma$ over all trees in $X_{ab}$ (where $a,b$ are siblings)\n",
    "- Key lemma: (completes proof of theorem) there is an optimal tree (for $\\Sigma$) in $X_{ab}$ ($a,b$ were \"safe\" to merge)\n",
    "- Intuition: can make an optimal tree better by pushing $a,b$ as deep as possible (since $a,b$ have smallest frequencies)\n",
    "\n",
    "### Proof of key lemma\n",
    "\n",
    "- By exchange argument. let $T^{*}$ be any tree that minimizes $L(T)$ for $\\Sigma$. let $x,y$ be siblings at the deepest level of $T^{*}$\n",
    "- The exchange: obtain $\\hat{T^{'}}$ from $T^{*}$ by swapping $a$ <-> $x$, $b$ <-> $y$\n",
    "- Bote: $\\hat{T} \\in X_{ab}$ (by choice of $x,y$)\n",
    "- To finish: will show that $L(\\hat{T}) \\le L(T^{*})$\n",
    "    - $\\hat{T}$ also optimal, completes \n",
    "- Reason\n",
    "    - $L(T^{*}) - L(\\hat{T}) = (p_{x}-p_{a}) + (p_{y}-p_{b}) \\ge 0$ \n",
    "    \n",
    "### Running time\n",
    "\n",
    "- Naive implementation: $O(n^{2})$ where $n = |\\Sigma|$\n",
    "- Speed up: heap! (to perform repeated minimum computations)\n",
    "    - Use keys = frequencies\n",
    "    - After excluding the two-smallest-frequency symbols, re-insert the new meta-symbol (new key = sum of the 2 old ones)\n",
    "    - Iterative, O(nlogn)\n",
    "- Even faster: sorting + $O(n)$ additional work\n",
    "    - Manage (meta-)symbols using two queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    tuple_data (tuple) -- dictionary representing nodes in a tree and integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    num_nodes = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(data_array[0].split(\" \")[0])\n",
    "        del data_array[0] # delete first element, which is just the length of data\n",
    "        for item in data_array:\n",
    "            data_dict[str(index)] = int(item)\n",
    "            index += 1\n",
    "            \n",
    "    tuple_data = (data_dict, num_nodes)\n",
    "    return tuple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman(data_dict):\n",
    "    \"\"\"\n",
    "    Implement Huffman encoding\n",
    "    \n",
    "    Args:\n",
    "    data_dict (dictionary) -- stores key [index] - value [item] pair\n",
    "    \n",
    "    Returns:\n",
    "    return_tuple (tuple) -- stores max and min occurance of nodes in merge operation\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_dict_by_value = {k: v for k, v in sorted(data_dict.items(), key=lambda item: item[1])}\n",
    "    tree_merge_track = []\n",
    "\n",
    "    while len(sorted_dict_by_value) > 2:\n",
    "        first_two_items = dict(itertools.islice(sorted_dict_by_value.items(), 2)) # get two smallest values\n",
    "        first_node = \"\"\n",
    "        second_node = \"\"\n",
    "        new_weight = 0\n",
    "        for key, value in first_two_items.items():\n",
    "            if first_node == \"\":\n",
    "                first_node = key\n",
    "            else:\n",
    "                second_node = key\n",
    "            new_weight += value\n",
    "            del sorted_dict_by_value[key] # delete two smallest nodes\n",
    "\n",
    "        new_node = first_node + \" \" + second_node \n",
    "        tree_merge_track.append(new_node) \n",
    "        sorted_dict_by_value[new_node] = new_weight # create a new node that is a combination of the two smallest nodes\n",
    "        sorted_dict_by_value = {k: v for k, v in sorted(sorted_dict_by_value.items(), key=lambda item: item[1])}\n",
    "\n",
    "    # Find \"occurance\" of each node in merge operation\n",
    "    count_dict = {}\n",
    "    for item in tree_merge_track:\n",
    "        for char in item.split(\" \"):\n",
    "            if char not in count_dict:\n",
    "                count_dict[char] = 1\n",
    "            count_dict[char] += 1\n",
    "        \n",
    "    sorted_count_dict_by_value = {k: v for k, v in sorted(count_dict.items(), key=lambda item: item[1])}\n",
    "    insepction_array = []\n",
    "    for key,value in sorted_count_dict_by_value.items():\n",
    "        insepction_array.append(value)\n",
    "    \n",
    "    return_tuple = (max(insepction_array), min(insepction_array))\n",
    "    return return_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_obj = open_file(\"data/1-3-3-huffman.txt\")\n",
    "assert(huffman(tuple_obj[0])[0] == 19)\n",
    "assert(huffman(tuple_obj[0])[1] == 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## Dynamic programming\n",
    "\n",
    "### weighted independent sets\n",
    "\n",
    "- Input: a path graph $G = (V,E)$ with non-negative weights on vertices\n",
    "- Desired output: subset of nonadjacent vertices - an independent set of maximum total weight\n",
    "- Brute force: exponential time\n",
    "\n",
    "### Optimal structure\n",
    "\n",
    "- Reason about structure of an optimal solution\n",
    "- Let $S \\le V$ be a max-weight independent set (IS)\n",
    "- Let $v_{n}$ = last vertex of path\n",
    "\n",
    "### A case analysis\n",
    "\n",
    "- Case #1: suppose $v_{n} \\in S$. let $G^{'} = G$ with $v_{n}$ deleted\n",
    "    - Note: $S$ also an IS of $G^{'}$\n",
    "    - Note: $S$ must be a max-weight IS of $G^{'}$ - if $S^{*}$ was better, it would also be better than $S$ in $G$ (contradiction)\n",
    "- Case #2: suppose $v_{n} \\in S$\n",
    "    - Note: previous vertex $v_{n-1} \\notin S$ (by definition of IS). let $G^{''} = G$ with $v_{n-1}, v_{n}$ deleted\n",
    "    - Note: $S-\\{v_{n}\\}$ is an IS of $G^{''}$\n",
    "    - Note: must in fact be a max-weight IS of $G^{''}$ - if $S{*}$ is better than $S$ in $G^{''}$, then $S^{*}\\cup\\{v_{n}\\}$ is better than $S$ in $G$ (contradiction)\n",
    "    \n",
    "### Proposed algorithm\n",
    "\n",
    "- Recursively compute $s_{1}$ = max-weight IS of $G^{'}$\n",
    "- Recursively compute $s_{2}$ = max-weight IS of $G^{''}$\n",
    "- Return $s_{1}$ or $s_{2}\\cup\\{v_{n}\\}$, whichever is better\n",
    "- Runs in exponential time\n",
    "\n",
    "### Eliminating redundancy\n",
    "\n",
    "- Reformulate as a bottom-up iterative algorithm. let $G_{i}$ = 1st vertices of $G$\n",
    "- Populate array $A$ left to right with $A[i]$ = value of max-weight IS of $G_{i}$\n",
    "- Initialize $A[0] = 0, A[1] = w_{1}$\n",
    "- For $i = 2,3 \\dots n$\n",
    "    - $A[i] = max{A[i-1], A[i-2]+w_{i}}$\n",
    "- Runs in $O(n)$\n",
    "\n",
    "### Optimal solution\n",
    "\n",
    "- Trace back through filled-in array to reconstruct optimal solution\n",
    "- Key point: we know that a vertex $v_{i}$ belongs to a max-weight IS of $G_{i}$ <=> $w_{i}$ + max-weight IS of $G_{i-2} \\ge$ max-weight IS of $G_{i-1}$\n",
    "\n",
    "### A reconstruction algorithm\n",
    "\n",
    "Then trace back through filled-in array to reconstruct optimal solution\n",
    "- Let $A$ = filled-in array\n",
    "- Let $S$ = empty set\n",
    "- While $i \\ge 1$ \n",
    "    - If $A[i-1] \\ge A[i-2] + w_{i}$ (case 1 wins)\n",
    "        - Decrease i by 1\n",
    "    - Else (case 2 wins)\n",
    "        - Add $v_{i}$ to $S$ \n",
    "        - Decrease $i$ by 2\n",
    "- Return $S$\n",
    "\n",
    "### Principle of Dynamic Programming\n",
    "1. Identify a small number of sub-problems\n",
    "2. Can quickly + correctly solve \"larger\" sub-problems given the solutions to \"smaller sub-problems\"\n",
    "3. Solving all sub-problems computes final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    tuple_data (tuple) -- dictionary representing a graph and integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    num_nodes = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(data_array[0].split(\" \")[0])\n",
    "        del data_array[0] # delete first element, which is just the length of data\n",
    "        for item in data_array:\n",
    "            data_dict[index] = int(item)\n",
    "            index += 1\n",
    "            \n",
    "    tuple_data = (data_dict, num_nodes)\n",
    "    return (data_dict, num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_weight_independent_set(data_dict, num_nodes):\n",
    "    \"\"\"\n",
    "    Find max-weight independent set using dynamic programming\n",
    "    \n",
    "    Args:\n",
    "    data_dict (dictionary) -- stores key [index] - value [item] pair\n",
    "    num_nodes (integer) -- total number of nodes in the set\n",
    "    \n",
    "    Returns:\n",
    "    ret (string) -- binary represeting occurance of particualr integers in the set\n",
    "    \"\"\"\n",
    "    \n",
    "    A = {}\n",
    "    A[0] = 0\n",
    "    A[1] = data_dict[1]\n",
    "    for i in range(2, num_nodes + 1):\n",
    "        A[i] = max(A[i-1], A[i-2] + data_dict[i])\n",
    "\n",
    "    S = set()\n",
    "    while num_nodes > 1:\n",
    "        if A[num_nodes-1] >= A[num_nodes-2] + data_dict[num_nodes]:\n",
    "            num_nodes -= 1\n",
    "        else:\n",
    "            S.add(num_nodes)\n",
    "            num_nodes -= 2\n",
    "    if 2 not in S:\n",
    "        S.add(1)\n",
    "\n",
    "    ret = \"\"\n",
    "    for i in [1, 2, 3, 4, 17, 117, 517, 997]:\n",
    "        if i in S:\n",
    "            ret += \"1\"\n",
    "        else:\n",
    "            ret += \"0\"\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_obj = open_file(\"data/1-3-3-max-weight-independent-set1.txt\")\n",
    "assert(max_weight_independent_set(tuple_obj[0], tuple_obj[1]) == \"01010000\")\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-3-max-weight-independent-set2.txt\")\n",
    "assert(max_weight_independent_set(tuple_obj[0], tuple_obj[1]) == \"10100000\")\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-3-max-weight-independent-set.txt\")\n",
    "assert(max_weight_independent_set(tuple_obj[0], tuple_obj[1]) == \"10100110\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knapsack problem\n",
    "\n",
    "- Input: $n$ items\n",
    "    - Value $v_{i}$ (non-negative)\n",
    "    - Size $w_{i}$ (non-negative and integral)\n",
    "    - Capacity $W$ (non-negative integer)\n",
    "- Output: subset $S \\in \\{1 \\dots n\\}$ that maximizes $\\displaystyle\\sum_{i}v_{i}$ subject to $\\displaystyle\\sum_{i}w_{i} \\le W$\n",
    "\n",
    "Step #1\n",
    "- Let $S$ = a max-value solution\n",
    "- Suppose item $n \\notin S$. $S$ must be optimal with first $n-1$ items with capacity $W$\n",
    "    - If $S^{*}$ were better than $S$ with respect to 1st $n-1$ items, then this equally true with respect to all $n$ items -> contradiction\n",
    "- Suppose item $n \\in S$. $S-\\{n\\}$ must be optimal with first $n-1$ items with capacity $W-w_{n}$\n",
    "    - If $S^{*}$ has higher value than $S-\\{n\\}$ + totla size $\\le W-w_{n}$, then $S\\cup\\{n\\}$ has size $\\le W$ and value more than $S$ -> contradiction\n",
    "\n",
    "Step #2\n",
    "- Let $v_{i,x}$ = value of the best solution that\n",
    "- Uses only the first $i$ items\n",
    "- Has total size $\\le x$\n",
    "- For i = 1 to n and any x\n",
    "    - $v_{i,x}$ = max{$v_{i-1,x}$ (case when item $i$ in excluded), $v_{i} + v_{i-1,x-w_{i}}$ (case when item $i$ in included)}\n",
    "- If $w_{i} > x$, then $v_{i,x} = v_{i-1,x}$\n",
    "\n",
    "Step #3\n",
    "- Let $A$ = 2D array\n",
    "- Init $A[0,x] = 0$ for $x = 0 \\dots W$\n",
    "- For $i = 1 \\dots n$\n",
    "    - For $x = 0 \\dots W$\n",
    "        - $A[i,x] = max\\{A[i-1, x], A[i-1, x-w_{i}] + v_{i}\\}$ (ignore second term if $w_{i} \\gt x$)\n",
    "- Return $A[n,W]$\n",
    "- Runs in $\\theta(nW)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    tuple_data (tuple) -- dictionary representing value and weight, integer reprsenting total knapsack-size, integer reprsenting number of items \n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    knapsack_size = 0\n",
    "    num_items = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        knapsack_size = int(data_array[0].split(\" \")[0])\n",
    "        num_items = int(data_array[0].split(\" \")[1])\n",
    "        del data_array[0] # delete first element, which is just metadata\n",
    "        for item in data_array:\n",
    "            value = int(item.split(\" \")[0])\n",
    "            weight = int(item.split(\" \")[1])\n",
    "            data_dict[index] = (value, weight)\n",
    "            index += 1\n",
    "            \n",
    "    tuple_data = (data_dict, knapsack_size, num_items)\n",
    "    return tuple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack(data_dict, knapsack_size, num_items):\n",
    "    \"\"\"\n",
    "    Implement dynamic programming algorithm for knapsack problem\n",
    "    \n",
    "    Args:\n",
    "    data_dict (dictionary) -- has value and weight of each item\n",
    "    knapsack_size (integer) -- total knapsack size/weight\n",
    "    num_items (integer) -- total number of items\n",
    "    \n",
    "    Returns:\n",
    "    result (integer) -- maximum value achievable given the size\n",
    "    \"\"\"\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in range(0, num_items + 1):\n",
    "        A.append([])\n",
    "        for j in range(0, knapsack_size + 1):\n",
    "            A[i].append(0)\n",
    "\n",
    "\n",
    "    for i in range(1, num_items + 1):\n",
    "        for j in range(0, knapsack_size + 1):\n",
    "            if data_dict[i][1] > j:\n",
    "                A[i][j] = A[i-1][j]\n",
    "            else:\n",
    "                A[i][j] = max(A[i-1][j], A[i-1][j-data_dict[i][1]] + data_dict[i][0])\n",
    "\n",
    "    result = A[num_items][knapsack_size]\n",
    "    return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_obj = open_file(\"data/1-3-4-knapsack1.txt\")\n",
    "assert(knapsack(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 14)\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-4-knapsack2.txt\")\n",
    "assert(knapsack(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 150)\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-4-knapsack3.txt\")\n",
    "assert(knapsack(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 147)\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-4-knapsack4.txt\")\n",
    "assert(knapsack(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 8)\n",
    "\n",
    "tuple_obj = open_file(\"data/1-3-4-knapsack.txt\")\n",
    "assert(knapsack(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 2493893)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path (string) -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    tuple_data (tuple) -- dictionary representing value and weight, integer reprsenting total knapsack-size, integer reprsenting number of items\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    knapsack_size = 0\n",
    "    num_items = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        knapsack_size = int(data_array[0].split(\" \")[0])\n",
    "        num_items = int(data_array[0].split(\" \")[1])\n",
    "        del data_array[0] # delete first element, which is just metadata\n",
    "        for item in data_array:\n",
    "            value = int(item.split(\" \")[0])\n",
    "            weight = int(item.split(\" \")[1])\n",
    "            data_dict[index] = (value, weight)\n",
    "            index += 1\n",
    "            \n",
    "    tuple_data = (data_dict, knapsack_size, num_items)\n",
    "    return tuple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_big(data_dict, knapsack_size, num_items):\n",
    "    \"\"\"\n",
    "    Implement (optimized) dynamic programming algorithm for large knapsack problem\n",
    "    \n",
    "    Args:\n",
    "    data_dict (dictionary) -- has value and weight of each item\n",
    "    knapsack_size (integer) -- total knapsack size/weight\n",
    "    num_items (integer) -- totla number of items\n",
    "    \n",
    "    Returns:\n",
    "    result (integer) -- maximum value achievable given the size\n",
    "    \"\"\"\n",
    "    \n",
    "    A = []\n",
    "    for i in range(0, 2):\n",
    "        A.append([]) \n",
    "        for j in range(0, knapsack_size + 1):\n",
    "            A[i].append(0)\n",
    "\n",
    "    i = 1\n",
    "    while i <= num_items:\n",
    "        A[1][0:data_dict[i][1]] = A[0][0:data_dict[i][1]][:]\n",
    "        for j in range(data_dict[i][1], knapsack_size + 1):\n",
    "            if data_dict[i][1] > j:\n",
    "                A[1][j] = A[0][j]\n",
    "            else:\n",
    "                A[1][j] = max(A[0][j], A[0][j-data_dict[i][1]] + data_dict[i][0])\n",
    "        A[0] = A[1][:] # copy array by value, not reference\n",
    "        print(str(i) + \" -> \" + str(A[1][knapsack_size]))\n",
    "        i += 1\n",
    "        \n",
    "    result = A[num_items][knapsack_size]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_obj = open_file(\"data/1-3-4-knapsack-big.txt\")\n",
    "assert(knapsack_big(tuple_obj[0], tuple_obj[1], tuple_obj[2]) == 4243395)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence alignment\n",
    "\n",
    "- Input: strings $X = x_{1} \\dots x_{m}$, $Y = y_{1} \\dots y_{m}$ over some alphabet (like $\\{A,C,G,T\\}$)\n",
    "    - Penalty $\\alpha_{gap} \\ge 0$ for inserting a gap, $\\alpha_{ab}$ for matching $a$ and $b$\n",
    "- Alignment: insert gaps to equalize length of string\n",
    "- Goal: alignment with minimum possible total penalty\n",
    "\n",
    "Final position of string can be one of\n",
    "- Case1: $x_{m}$ and $y_{n}$ matched\n",
    "- Case2: $x_{m}$ is matched with a gap\n",
    "- Case3: $y_{n}$ is matched with a gap\n",
    "\n",
    "Let $X^{'} = X - x_{m}$ and $Y^{'} = Y - y_{m}$ \n",
    "- Case1: alignment of $X^{'}$ and $Y^{'}$ is optimal\n",
    "- Case2: alignment of $X^{'}$ and $Y$ is optimal\n",
    "- Case3: alignment of $X$ and $Y^{'}$ is optimal\n",
    "\n",
    "Subproblem $(X_{i}m Y_{j})$\n",
    "- $X_{i}$ = 1st $i$ letters of $X$\n",
    "- $Y_{j}$ = 1st $j$ letters of $Y$\n",
    "\n",
    "### Recurrence\n",
    "\n",
    "- Let $P_{ij}$ = penalty of optimal alignment of $X_{i}$ and $Y_{j}$\n",
    "- For all i = 1 to n and j = 1 to n, $P_{ij}$ is the **minimun** of the following three cases\n",
    "- Case1: $\\alpha_{x_{i}y_{j}}$ + $P_{i-1,j-1}$\n",
    "- Case2: $\\alpha_{gap}$ + $P_{i-1,j}$\n",
    "- Case3: $\\alpha_{gap}$ + $P_{i,j-1}$\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "- Let $A$ = 2D array\n",
    "- $A[i,0] = A[0,j] = i * \\alpha_{gap} \\forall i \\ge 0$\n",
    "- For $i = 1 \\dots m$\n",
    "    - For $j = 1 \\dots n$\n",
    "        - $A[i,j]$ = $min\\{A[i-1,j-1]+\\alpha_{x_{i}y_{j}}, A[i-1,j]+\\alpha_{gap}, A[i,j-1]+\\alpha_{gap}\\}$\n",
    "- Runs in $O(mn)$\n",
    "\n",
    "### Reconstructing a solution\n",
    "        \n",
    "- Trace back through filled-in table $A_{i}$ starting at $A[m,n]$\n",
    "- When reaching subproblem $A[i,j]$\n",
    "    - If $A[i,j]$ filled using case1, match $x_{i}$ and $y_{j}$, and go to $A[i-1, j-1]$\n",
    "    - If $A[i,j]$ filled using case2, match $x_{i}$ and a gap, and go to $A[i-1, j]$\n",
    "    - If $A[i,j]$ filled using case3, match $y_{j}$ and a gap, and go to $A[i, j-1]$\n",
    "- If $i=0$ or $j=0$, match remaining substring with gaps\n",
    "- Runs in $O(m+n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal binary search tree\n",
    "\n",
    "- What is the best search tree for a given set of keys?\n",
    "- Input: frequencies $p_{1} \\dots p_{n}$ for items $1 \\dots n$ (assume items in sorted order $1 \\lt \\dots \\lt n$)\n",
    "- Goal: compute a valid search tree that minimizes weighted search time\n",
    "\n",
    "$C(T) = \\displaystyle\\sum_{i}P_{i}*$[search time for $i$ in $T$]\n",
    "\n",
    "- Ex. if $T$ is a red-black tree, then $C(T) = O(logn)$ (assuming $\\displaystyle\\sum_{i}P_{i} = 1$)\n",
    "\n",
    "### Comparison with Huffman codes\n",
    "\n",
    "- Similarities \n",
    "    - Output = a binary tree\n",
    "    - Goal is (essentially) to minimize average depth with respect to given probabilities\n",
    "- Difference\n",
    "    - With Huffman codes, contraint was prefix-freeness, but here contraint is search tree property\n",
    "\n",
    "### Optimal structure\n",
    "\n",
    "- Suppose an optimal BST for keys $\\{1,2 \\dots n\\}$ has root $r$, left subtree $T_{1}$, right subtree $T_{2}$\n",
    "- Then, subtrees $T_{1}$ and $T_{2}$ are optimal BSTs for the keys $\\{1 \\dots r-1\\}$ and $\\{r+1 \\dots n\\}$\n",
    "- Proof\n",
    "    - Let $T$ be an optimal BST for keys $\\{1 \\dots n\\}$ with frequencies $p_{1} \\dots p_{n}$\n",
    "    - Suppose $T$ has root $r$\n",
    "    - Suppose for contradiction that $T_{1}$ is not optimal for $\\{1,2 \\dots r-1\\}$ (other case is similar) with $C(T^{*}_{1}) \\lt C(T_{1})$\n",
    "    - Obtain $T^{*}$ from $T$ by \"cutting + pasting\" $T^{*}_{1}$ in for $T_{1}$\n",
    "    - Need to show $C(T^{*}) \\lt C(T)$\n",
    "    - $C(T) = \\displaystyle\\sum_{i=1}^{n}p_{i}$[search time for $i$ in $T$] = $p_{r} + \\displaystyle\\sum_{i=1}^{r-1}p_{i}$[search time for $i$ in $T$]$ + \\displaystyle\\sum_{i=r+1}^{n}p_{i}$[search time for $i$ in $T$]$ = \\displaystyle\\sum_{i=1}^{n}p_{i} + \\displaystyle\\sum_{i=1}^{r-1}p_{i}$[search time for $i$ in $T_{1}$]$ + \\displaystyle\\sum_{i=r+1}^{n}p_{i}$[search time for $i$ in $T_{2}$] = a constant (independent of $T$) + $C(T_{1}) + C(T_{2})$\n",
    "    - $C(T^{*}_{1}) \\lt C(T_{1})$ implies $C(T^{*}) \\lt C(T)$, contradicting optimality of $T$\n",
    "\n",
    "### Relevant subproblems\n",
    "\n",
    "- Key $\\{1 \\dots n\\}$ = original items. For which subsets $S \\in \\{1 \\dots n\\}$ might we need to compute the optimal BST for $S$?\n",
    "    - Continuous interval ($S = \\{i, i+1 \\dots j-1, j\\}$) for every $i \\le j$\n",
    "    \n",
    "### Recurrence\n",
    "\n",
    "- For $1 \\ge i \\ge j \\ge n$, let $C_{ij}$ = weighted search cost of optimal BST for items $\\{i, i+1 \\dots j-1, j\\}$ with properties $\\{p_{i}, p_{i+1} \\dots p_{j}\\}$\n",
    "- For every $1 \\ge i \\ge j \\ge n$\n",
    "\n",
    "$C_{ij} = \\underset{r=i}{\\text{min}}\\left[\\displaystyle\\sum_{k=1}^{j}P_{k}+C_{i,r-1}+C_{r+1,j}\\right]$ where $C_{i,r-1}, C_{r+1,j} = 0$ if $x>y$\n",
    "\n",
    "- Correctness: optimal substructure narrows candidates down to $(j-i+1)$ possibilities, recurrence picks the best by brute force\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "- Let $A$ = 2D array\n",
    "- For $s = 0 \\dots n-1$ ($s$ represent $j-i$)\n",
    "    - for $i = 1 \\dots n$ (so $i+s$ plays role of $j$)\n",
    "        - $A[i, i+s]$ = $\\underset{r=i}{\\text{min}}\\left[\\displaystyle\\sum_{k=i}^{i+s}P_{k}+A[i,r-1]+A[r+1,i+s]\\right]$ where $A[i,r-1]+A[r+1,i+s] = 0$ if first index $\\ge$ second index\n",
    "- Return $A[1,n]$\n",
    "- Runs in $\\theta({n^{3}})$ ($\\theta({n^{2}})$ subproblems, $\\theta(j-i)$ time to compute $A[i,j]$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
