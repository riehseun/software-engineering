{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c96bfe5-9eb0-450c-be39-aeb5ecd03cc1",
   "metadata": {},
   "source": [
    "# Overview (Example: Twitter)\n",
    "\n",
    "## Requirement clarification\n",
    "\n",
    "- Do users post tweets and follow other people?\n",
    "- Do users search tweets?\n",
    "- Need to display user timeline?\n",
    "- Need to push notification on new tweets?\n",
    "- Need to display trending topics?\n",
    "- Do tweets contain photos and videos?\n",
    "- Are we discussing backend only or frontend too?\n",
    "\n",
    "## System estimation\n",
    "\n",
    "- Numer of tweets? Number of users? \n",
    "- Size of storage?\n",
    "- Network bandwidth?\n",
    "\n",
    "## System interface\n",
    "\n",
    "- What APIs are expected?\n",
    "\n",
    "## Data model\n",
    "\n",
    "- User (UserID, Name, Email, CreationDate, LastLogin, etc)\n",
    "- Tweet (TweetID, Content, TimeStamp, etc)\n",
    "- UserFollow (UserID1, UserID2)\n",
    "\n",
    "## High-level design\n",
    "\n",
    "- Multiple app servers to do read/write with LoadBalancer in front.\n",
    "- Efficient DB to store all tweets and support large number of reads.\n",
    "- Distributed file storage to store photos and videos.\n",
    "\n",
    "## Detailed design\n",
    "\n",
    "- How to partition data and distribute it to multiple DBs.\n",
    "- How to handle \"hot\" users.\n",
    "- At which layer should we introduce cache. \n",
    "\n",
    "## Identify bottleneck\n",
    "\n",
    "- Is there a single point of failure?\n",
    "- Do we have replicas of data?\n",
    "- Do we have availability set of app servers?\n",
    "- Do we monitor servers and get alerts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dc812-822e-40ce-8e86-074dc8472fcf",
   "metadata": {},
   "source": [
    "# Design TinyURL (URL shortening)\n",
    "\n",
    "- Short link. This is used to save a lot of space. This URL must not be guessable.\n",
    "- When users clock short link, they are redirected to the original URL.\n",
    "\n",
    "## Capacitiy Estimate\n",
    "\n",
    "Example: traffic\n",
    "- 500M URL shortening per month.\n",
    "- 100:1 read:write ratio.\n",
    "- Numer of redirections per month: 100 * 500M = 50B\n",
    "- Queries per second: 500M / (30 days * 24 hrs * 3600 seconds) = 200 URLs/s\n",
    "- URL redirections per second: 100 * 200 URLs/s = 20k URLs/s \n",
    "\n",
    "Example: storage\n",
    "- Assume we store URL shortening request for 5 yrs.\n",
    "- Total number of objects to store: 500M * 5 yrs * 12 months = 30 billion\n",
    "- Assume each object is around 500 bytes.\n",
    "- Total storage: 30 billion * 500 bytes = 15TB\n",
    "\n",
    "Example: Bandwidth\n",
    "- Write (Queries per second is 200 URLs): 200 * 500 bytes = 100 kB/s\n",
    "- Read (URL redirections per second is 20k URLs): 20k * 500 bytes = 10 MB/s\n",
    "\n",
    "Example: Memory\n",
    "- Assume 20% of URLs generate 80% of traffic. (Hot URLs)\n",
    "- Request per day: 20k URLs/s * 3600 seconds * 24 hrs = 1.7 billion\n",
    "- To cache 20% of these requests: 0.2 * 1.7 billion * 500 bytes = 170 GB\n",
    "    - There will be duplicate requests of the same URLs, so the actual required memory will be less.\n",
    "    \n",
    "## System API\n",
    "\n",
    "- createURL(api_dev_key, original_url)\n",
    "    - api_dev_key: API developer key of registered account.\n",
    "    - original_url: URL to be shortened.\n",
    "- deleteURL(api_dev_key, url_key)\n",
    "    - url_key: shortened URL.\n",
    "- To prevent user abuse, limit \"api_dev_key\" to certain number of creations and redirections per time period.     \n",
    "   \n",
    "## Database\n",
    "\n",
    "- Billions of records.\n",
    "- Each object is small. (500k)\n",
    "- Read heavy.\n",
    "- Since there is no relationship between records, No SQL should be chosen.\n",
    "- Schema \"URL\": Hash(varchar 16, PK), OriginalURL(varchar), CreationDate(datetime), ExpirationDate(datetime), UserID(int) \n",
    "- Schema \"User\": UserID(int), Name(varchar), Email(varchar), CreationDate(datetime), LastLogin(datetime)\n",
    "\n",
    "## Encoding algorithm\n",
    "\n",
    "- Want to generate characters at the end of the URL.\n",
    "- Assume base64 encoding.\n",
    "    - 6 letters 64^6 = 68.7 billion possible strings.\n",
    "    - 8 letters 64^8 = 281 trillion possible strings.\n",
    "- If multiple users enter the same URL, they can get the same shortened URL, which is not good.\n",
    "- What if randomly generate 6 letter strings beforehand and store them into DB?\n",
    "    - If a key is used, then it should be marked as used.\n",
    "    - What is two or more servers are trying the use the same key?\n",
    "        - One table for keys not in used, one table for keys in use.\n",
    "        - Load some keys in memory to give to the servers and at the same time move them to \"Used\" table.\n",
    "     - DB size: 6 (characters per key) * 68.7 billion (unique keys) = 412GB\n",
    "\n",
    "## Data partitioning and replication\n",
    "\n",
    "- Range based partitioning\n",
    "    - Partiion based on the first letter of URL hash keys.\n",
    "    - This could lead to unbalanced partitioning.\n",
    "- Hash based partitioning\n",
    "    - Use hash function to map \"key\" to a number between [1,255]\n",
    "\n",
    "## Cache\n",
    "\n",
    "- Cache URLs that are frequently accessed.\n",
    "\n",
    "## Load balancer\n",
    "\n",
    "- Between Client and App servers.\n",
    "- Between App servers and DB servers.\n",
    "- Between App servers and cache servers.\n",
    "\n",
    "## DB clean up\n",
    "\n",
    "- Lightweight cleanup service that removes expired links from cache and storage (Also put the key back into key DB to be reused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224749f-e2c2-4f6b-b047-e5f3f4d434e3",
   "metadata": {},
   "source": [
    "# Design Pastebin\n",
    "\n",
    "- Store texts and access the data using URLs.\n",
    "\n",
    "## Capacity estimate\n",
    "\n",
    "- There will be reads of URLs than new pastebin creation. Assume 5:1 ratio.\n",
    "- Traffic: assume 1 million pastes per day (then, 5 million reads per day)\n",
    "    - New pastes per second: 1M / (24 hrs * 3600 seconds) = 12 pastes/s\n",
    "    - Paste reads per second: 5M / (24 hrs * 3600 seconds) = 58 pastes/s\n",
    "- Storage: users can upload max 10MB data. Assume on average 10KB data.\n",
    "    - We store 1M * 10KB = 10GM per day.\n",
    "    - Storing this data for 10 yrs requires 36TB.\n",
    "    - With 70& capacity model (we don't use more than 70% capacity at any point), we need 51.4TB.\n",
    "- Bandwidth: \n",
    "    - With 12 pastes/s writes, we need 12/s * 10KB = 120KB/s ingress.\n",
    "    - With 58 pastes/s read, we need 58/s * 10KB = 580KB/s ingress.\n",
    "- Memory: assume 20/80 rule \n",
    "    - 0.2 * 5M * 10KB = 10GM memory need to cache.\n",
    "    \n",
    "## System API\n",
    "\n",
    "- addPaste(api_dev_key, paste_data)\n",
    "    - api_dev_key: API developer key of registered account\n",
    "    - paste_data: text data to paste.\n",
    "- getPaste(api_dev_key, api_paste_key)\n",
    "    - api_paste_key: string representing the paste key of paste to be retrieved.\n",
    "- deletePaste(api_dev_key, api_paste_key)\n",
    "\n",
    "## Database\n",
    "\n",
    "- Billions of records.\n",
    "- Each object is medium sized (max 10MB)\n",
    "- Read heavy\n",
    "- No relations\n",
    "- Schema \"Paste\": Hash(varchar 16, PK), ContentKey(varchar), CreationDate(datetime), ExpirationDate(datetime), UserID(int)\n",
    "- Schema \"User\": UserID(int), Name(varchar), Email(varchar), CreationDate(datetime), LastLogin(datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb70bb-5847-4448-a3b6-d311deae18ec",
   "metadata": {},
   "source": [
    "# Design Instagram\n",
    "\n",
    "## Capacity estimate\n",
    "\n",
    "- Assume \n",
    "    - 500M total users with 1M daily active users.\n",
    "    - 2M new photos every day (23 new photos / s)\n",
    "    - Average photo size 200KB\n",
    "- Space for 1 day's amount of photo: 2M * 200KB = 400GB\n",
    "- If 10 yrs, 400GB * 365 * 10 = 1425TB\n",
    "\n",
    "## Database\n",
    "\n",
    "- Schema \"Photo\": PhotoID(int, PK), UserID(int), PhotoPath(varchar), PhotoLatitude(int), PhotoLongitude(int), UserLatitude(int), UserLongitude(int), CreationDate(datetime)\n",
    "- Schema \"User\": UserID(int, PK), Name(varchar), Email(varchar), CreationDate(datetime), LastLogin(datetime)\n",
    "- Schema \"UserFollow\": FollowerID(int, PK), FolloweeID(int, PK)\n",
    "\n",
    "## Data size\n",
    "- Assume \"int\" and \"datetime\" are 4 bytes.\n",
    "- User \n",
    "    - UserID(4 bytes) + Name(20 bytes) + Email(32 bytes) + DateOfBirth(4 bytes) + CreationDate(4 bytes) + LastLogin(4 bytes) = 68 bytes\n",
    "    - With 500M users, we need 68 * 500M = 32GB\n",
    "- Photo\n",
    "    - PhotoID(4 bytes) + UserID(4 bytes) + PhotoPath(256 bytes) + PhotoLatitude(4 bytes) + PhotoLongitude(4 bytes) + UserLatitude(4 bytes) + UserLongitude(4 bytes) + CreationDate(4 bytes) = 284 bytes\n",
    "    - With 2M photos everyday, we need 284 * 2M = 0.5GB\n",
    "    - For 10 yrs, we need 1.88TB\n",
    "- UserFollow\n",
    "    - Assume each user follows 500 other users and each row in UserFollow table is 8 bytes: 5M * 500 * 8 bytes = 1.82TB\n",
    "- Total space: 32GB + 1.88TB + 1.82TB = 3.7TB\n",
    "\n",
    "## Component design\n",
    "\n",
    "- Split read and write services such as \"uploads\" don't hog the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11fa68-552f-458a-b930-bfe594727e80",
   "metadata": {},
   "source": [
    "# Design Dropbox\n",
    "\n",
    "- Store data on remote servers.\n",
    "- Read and write will be huge. (assume the same ratio)\n",
    "- Fill will be stored in small chunks (assume 4MB)\n",
    "\n",
    "## Capacity estimate\n",
    "\n",
    "- Assume 500M total users, 100 daily active users.\n",
    "- Assume each user connects from three different devices.\n",
    "- Assume each user has 200 files/photos, so there we have 100 billion total files.\n",
    "- Assume average file size is 100KB. We have 100B * 100KB = 10PB\n",
    "- Assume 1M active connections per minute.\n",
    "\n",
    "## High-level design\n",
    "\n",
    "- Need to store file metadata (name, size, path, shared with who, etc)\n",
    "\n",
    "## Component design\n",
    "\n",
    "- Client\n",
    "    - Internal metadata DB: keeps metadata in the client to save round-trips to update remote metadata.\n",
    "    - Chunker: splits files into small pieces.\n",
    "    - Watcher: monitors workspace and notify Indexer of any user actions. Listens to changes in other clients.\n",
    "    - Indexer: processes events from Watcher and updates internal metadata DB. Also, updates remote DB via talking to remote sync service.\n",
    "- Metadata DB\n",
    "- Sync service\n",
    "- Message queue\n",
    "    - Handles communication between clients and sync service.\n",
    "- Block storage\n",
    "    - Stores chunks of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4da6a-5f7a-412f-942f-ccbdee6da671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
